J. Child Lang.  (), –. © Cambridge University Press 
doi:./S

Auditory perception and word recognition in

Cantonese-Chinese speaking children with and without

Speciﬁc Language Impairment*

JOANNA C. KIDD, KATHY K. SHUM, ANITA

M.-Y. WONG, CONNIE S.-H. HO A N D TERRY K. AU

The University of Hong Kong

(Received  April  – Revised  March  – Accepted  September  –

First published online  December )

A B S T R A C T

Impairment

(SLI),

Auditory processing and spoken word recognition diﬃculties have been
observed in Speciﬁc Language
raising the
possibility that auditory perceptual deﬁcits disrupt word recognition
and, in turn, phonological processing and oral language. In this study,
ﬁfty-seven kindergarten children with SLI and ﬁfty-three language-
typical age-matched controls were assessed with a speech-gating task
to measure spoken word recognition, psychophysical tasks to measure
auditory Frequency Modulation (FM) detection and Frequency
Discrimination (FD),
of
phonological processing and oral language. As a group, children with
SLI took signiﬁcantly longer
to
recognize words with high neighborhood density, perhaps reﬂecting
subpar phonological
representations. FM, but not FD, was
signiﬁcantly worse in SLI. However, while both poorer speech-gating
performance and poorer auditory thresholds (FM) were evident in
SLI, spoken word recognition did not mediate any relation between
auditory perception and either phonological processing or oral language.

and standardized psychometric

than language-typical controls

tests

[*] We thank the children, parents, and staﬀ of participating kindergartens, speech-language
therapists at the Child Assessment Services (Hong Kong SAR), and our team of dedicated
research assistants for their support. We thank K. K. Luke for sharing his Cantonese
spoken-word corpus, and John Hogben and Genevieve McArthur
for helpful
discussions. This work was supported by the Hong Kong Research Grant Council
(Grant GRFH to Anita Wong) and the University of Hong Kong (Grant
 to Terry Au, and a post-doc fellowship to Joanna Kidd). Address for
correspondence: Terry Kit-fong Au, Department of Psychology, The University of
Hong Kong, Pokfulam Road, Hong Kong, China. tel: ()  ; e-mail:
terryau@hku.hk



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

fail

(SLI)

I N T R O D U C T I O N
Children with Speciﬁc Language Impairment
to develop
expressive and/or receptive oral language at the same rate and/or to the
same extent as typically developing children, despite adequate intelligence,
peripheral sensory functioning, exposure to language, and no neurological,
emotional, or social dysfunction (Bishop, ; Leonard, ; Rice,
). Compared to same-age peers, these children demonstrate an uneven
proﬁle of abilities across domains of language, with most experiencing
diﬃculties
in grammatical morphology and syntax, but many also
demonstrating diﬃculties in lexical and pragmatic skills (Leonard, ).
Diﬃculty in lexical processes underlying spoken word recognition is well
documented in SLI: ineﬃciency or inaccuracy in establishing, accessing,
selecting, and retrieving from stored representations of spoken language
(Dollaghan, ). For example, children with SLI tend to have smaller
overall expressive/receptive vocabulary (Hick, Botting & Conti-Ramsden,
) and impaired phonological processing (Briscoe, Bishop & Norbury,
), use fewer diﬀerent words per utterance (Rice, Redmond &
Hoﬀman, ; Wong, Klee, Stokes, Fletcher & Leonard, b), and are
less accurate in nonword repetition (Estes, Evans & Else-Quest, ).

Multiple accounts have been proposed to explain the diﬀerent language
deﬁcits observed in children with SLI, and much research has focused on
the grammatical deﬁcit account and the processing deﬁcit account
(Joanisse & Seidenberg, ; Leonard, ). Some researchers have also
explored the possibility of deﬁcits
such as
lower-level auditory perception (Corriveau, Pasquini & Goswami, ;
McArthur & Bishop, a, b; Tallal & Piercy, ), but little
research to date has focused on auditory perception and word recognition
deﬁcits within the same children with SLI (but see Montgomery, ).
The present study responded to this research gap by focusing on lexical
access for spoken word recognition in SLI, and whether and how it might
be related to auditory perception.

in speciﬁc mechanisms

Spoken word recognition and the speech-gating task
Spoken word recognition occurs when auditory perceptual input activates a
single lexical phonological representation. Activation begins upon receipt of
auditory input and is updated as the input unfolds. The activation seems to
be graded according to word- and cohort-related factors, and multiple words
can be activated in parallel and actively compete until a single match is
selected (McMurray, Samelson, Lee & Tomblin, ). Word recognition
can thus be conceptualized as selective elimination from an activated
cohort of potential targets until the ‘isolation point’ – the point within the
word for which no other word matches are possible (Marslen-Wilson, ).



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

are

rather

systematically

stored more

acoustically similar words) have been posited to drive

Spoken word recognition may be facilitated by developmental restructuring
of phonological representations. That is, ongoing reorganization of the lexicon
such that representations are stored for accuracy and expediency (e.g. Metsala
& Walley, ; Walley, Metsala & Garlock, ); with development,
primarily between ages one to eight (Fowler, ), words with overlapping
phonological properties
for better
diﬀerentiation. Word frequency and neighborhood density (i.e. the number
lexical
of
restructuring. High-
should have
better-developed representations because the former are activated more
often. Words from high-density phonological neighborhoods should be
under relatively strong pressure to diﬀerentiate from other lexical entries to
enable recognition (Charles-Luce & Luce, ; Garlock, Walley &
Metsala, ). Lexical restructuring has been observed across alphabetic
(Ziegler & Goswami, ) – which map morphemes onto
languages
phonemes or phoneme strings – as well as a logographic language that maps
morphemes consistently onto syllables (i.e. Chinese; Kidd, Shum, Ho &
Au, ).

than low-frequency words

to reﬂect

is thought

Speech-gating, a behavioral task that estimates the point within spoken
words beyond which correct recognition is possible (Allopenna, Magnuson
& Tanenhaus, ; Grosjean, ), has been used productively and
widely to study spoken word recognition and lexical development models.
In a typical non-contextual forward speech-gating task, spoken words are
presented from their onset in segments (or ‘gates’) typically  ms in
length, with word identiﬁcation attempted after hearing each gate. On each
trial, an additional gate is added, with trials only ending when each word
has been heard in its entirety. The accumulated time increment at which
recognition occurs without subsequent change of mind (the ‘acceptance
point’)
the temporal window over which word
recognition occurs. This temporal window has been suggested to directly
reﬂect the underlying organization of the representation: well-established
structure facilitates expedient word recognition because the cohort of
incorrect matches
and less-established
representations impede word recognition because the cohort remains
protractedly active (Metsala, ). Thus the speech-gating task has
been used to quantify the underlying structure of
the phonological
representations supporting spoken word recognition. Consistent with this,
Metsala observed that
time taken to correctly identify gated words
decreased with age, and that word frequency and neighborhood density
eﬀects were predicted by lexical restructuring. These ﬁndings have been
replicated in other gating studies (Griﬃths & Snowling, ; Kidd et al.,
; Metsala, Stavrinos & Walley, ).

rapidly discounted,

can be



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

Speech-gating in SLI
Speech-gating has been used for assessing spoken word recognition in SLI.
Dollaghan () compared SLI children with typically developing
age-matched controls on their recognition of gated familiar and unfamiliar
words. There were no group diﬀerences for familiar words, but children
with SLI needed to hear more of the unfamiliar words to recognize them
than did the controls. These ﬁndings did not support a task-related
impairment. Instead,
the deﬁcit seemed speciﬁc to the phonological
representations of unfamiliar words and the ability to distinguish them
from the better-established representations of familiar words. Accessing
less-established representations probably increases processing demands,
leaving word recognition vulnerable. Children with SLI were also less
likely to produce the correct initial consonant at the earliest gate for all
word types, suggesting lower-level auditory perceptual deﬁcits that impede
the initial acoustic-phonetic analysis (Dollaghan, ).

Montgomery () used speech-gating of highly familiar words to examine
whether children with SLI were impaired in ‘lexical mapping’ (i.e. lexical
access and lexical activation) – the stage when auditory perceptual
input
undergoes acoustic-phonetic analysis. No group diﬀerences were found
between children with SLI and their typically developing peers matched on
either age or vocabulary, arguing against word recognition and low-level
auditory perceptual deﬁcits
(Sutherland & Gillon, ).
Mainela-Arnold, Evans, and Coady () likewise observed neither group
diﬀerence in spoken word recognition isolation points between SLI children
and age-matched controls, nor any interaction between SLI status, word
frequency,
children with SLI
vacillated more between the target and incorrect cohort items after the
isolation point, suggesting that word recognition in SLI is more vulnerable
to interference from competing activated representations. This ﬁnding was
replicated by Marshall and van der Lely ().

and neighborhood density. However,

in SLI

isolation points

Wong, Kidd, Ho, and Au (a) found that Cantonese-Chinese speaking
children with SLI (particularly those with comorbid dyslexia) had
signiﬁcantly later
for high-frequency words, and for
high-density words, compared to language-typical peers as well as children
who had a history (but no current diagnosis) of SLI. These ﬁndings suggest
that the phonological representations of children with SLI have not been
restructured to the same extent as those of typically developing children.
Importantly, the subpar speech-gating performance observed in SLI could
not be attributed to overall poorer vocabulary because the deﬁcit was
limited to high-frequency words and high-neighborhood-density words.

Collectively, the ﬁndings on speech-gating and SLI hint at diﬃculties in
some aspects of spoken word recognition in SLI, particularly in Cantonese



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

Chinese. Wong et al.’s (a) study stands alone in the literature by
reporting frequency and density eﬀects in SLI using speech-gating.
However, given their focus on SLI–dyslexia comorbidity, of the twenty
children with a current diagnosis of SLI, only ten had SLI without
comorbid dyslexia. Therefore,
from
speech-gating regarding SLI remains unclear. The present study therefore
set out to take a closer look at these eﬀects, particularly those reported in
Wong et al.’s (a) study, in a much larger sample of children with SLI.

the robustness of

the ﬁndings

Phonological processing in SLI
Diﬃculties in phonological processing skills are well documented in SLI
(e.g. Bishop & Snowling, ). Snowling () hypothesized that
lead to poorer quality phonological
phonological deﬁcits might
representations, which might
in turn impair
the development of
phonological processing skills. Poorly established representations would be
diﬃcult to access and use, limiting phonological awareness (e.g. syllable
awareness, onset and rime awareness, phoneme deletion, etc.). Poorer
quality phonological representations might also impair access and retrieval
of phonological information, evident via slower and perhaps more errant
Rapid Automatized Naming (RAN) performance. Likewise, the ability to
maintain phonological
information in short-term memory suﬃcient to
either create or reﬁne phonological representations will likely inﬂuence the
quality of the representations (Claessen, Leitão, Kane & Williams, ).
There are potentially very informative relations between phonological
processing skills and the structure of
the underlying representation,
particularly in SLI. However, these relations have not been fully explored
using the speech-gating task to quantify the underlying structure of the
phonological representation. To do so was a goal of the present study.

Auditory perception in SLI
According to McMurray et al. (), subpar speech-gating suggests more
lexical decay – entropy in lexical representations – in SLI that prevents full
activation of some, if not all, phonological representations, rendering them
vulnerable to active competitors. This can explain why children with SLI
take longer than language-typical controls to reach the acceptance point
after the isolation point. However, it does not explain the diﬃculties with
the initial consonant in SLI reported by Dollaghan (); an additional
account is in order.

One possibility is that children with SLI have low-level auditory
perceptual deﬁcits (Dollaghan, ; McArthur & Bishop, ; Rosen,
). Tallal () reported that ‘language learning impaired’ children
were less able to diﬀerentiate and/or sequence brief tones (i.e. diﬀerent



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

tones at short inter-stimulus intervals, ISI). Such a deﬁcit in ‘temporal
processing’ was hypothesized to inhibit accurate perception of rapid
transitions in speech and to impair “the formation of distinct (categorical)
phonological representations, leading to delay or disruption in language”
(Benasich & Tallal, , p. ), also implicating phonological processing
skills, and potentially reading skills, in this causal chain (e.g. Tallal, ).
Auditory perception in SLI has been studied using variations of Tallal’s
auditory repetition task and other putative ‘temporal’ auditory tasks (e.g.
backward detection/recognition masking, gap detection, tracking of rapid
spatial changes; Rosen, ), with equivocal results. Importantly, the
potential mediating
the
hypothesized relation between auditory perception and phonological
processing skills has not been explicitly examined. No study has yet
examined whether both the quality of phonological
representations
pertinent to spoken word recognition – assessed with speech-gating – and
low-level auditory perception are impaired in the same individuals with
SLI. Without such empirical
information, these causal relations must
remain speculative.

representations

phonological

role

in

of

Tallal’s () auditory repetition task inherently conﬂates frequency
discrimination (FD) with general stimulus-based judgments. Note that
people with SLI often struggle with practice trials for the auditory
repetition task where tone discrimination, not temporal processing, was
stressed (Heath, Hogben & Clark, ), so poorer performance was not
limited to short ISIs during the task proper (e.g. Share, Jorm, McClean &
Matthews, ). Neither is poor performance necessarily limited to
‘temporal’ tasks – indeed Nickisch and Massinger () found reduced
performance in SLI only on tasks with an FD component, not those
assessing temporal processing. These
a
diﬃculty with FD in SLI, at times (though not always) exacerbated by
task-related pressures.

collectively suggest

results

in spectral

rapid changes

information. Deﬁcits

Poor FD may well turn out to undermine language learning, particularly in
tonal languages such as Cantonese Chinese (Wong, Ciocca & Yung, ).
Speech comprises
in
ﬁne-grained FD can mean diﬃculties discriminating spectral patterns in
speech signals, which can in turn degrade phonological representations
(McArthur & Bishop,
as
electrophysiological evidence, that at least some children with SLI perform
poorly on FD tasks (Hill, Hogben & Bishop, ; McArthur & Bishop,
a, b; ; McArthur, Ellis, Atkinson & Coltheart, ; Mengler,
Hogben, Mitchie & Bishop, ; Rinker, Kohls, Richter, Maas, Schultz &
Schecker, ), and continue to do so over time (Hill et al., ).
Nonetheless, because poor FD does not consistently predict SLI, more
research is needed to clarify this (Halliday & Bishop, ; Rosen, ).

a). There

is behavioral,

as well



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

to require

speech processing also seems
sensitivity to
Accurate
modulations
in frequency (Frisina, ). According to Bailey and
Snowling (), reduced sensitivity to frequency modulation (FM) when
young children are establishing and reﬁning phonological representations
may well aﬀect subsequent language ability. In a typical FM detection
task, the modulation rate is ﬁxed and the depth is varied across trials, and
the task is to diﬀerentiate modulated from un-modulated tones. Stefanatos,
Green, and Ratcliﬀ ()
found markedly reduced auditory-evoked-
responses to FM tones among children with SLI, but Tomblin, Abbas,
Records, and Brenneman () could not replicate this. Bishop, Carlyon,
Deeks, and Bishop () speculated that
the severity of receptive
issue, and their own research revealed a
impairments might be at
non-signiﬁcant
the
thresholds did not predict phonemic awareness. The exact contribution of
FM to speech recognition, then, remains unclear.

trend for elevated FM thresholds

in SLI, but

The present study
The mixed ﬁndings on FD and FM in SLI call for empirical clariﬁcation.
Crucially, little research has focused on how spoken word recognition deﬁcits
ﬁt with potential auditory perception deﬁcits in SLI. The present multilevel
investigation therefore examined FD, FM, and speech-gating within the
same children – children with a diagnosis of SLI, and age-matched controls.
With a relatively large sample, we focused on two main questions:

. Do children with SLI perform worse than age-matched language-typical
controls on spoken word recognition (assessed via speech-gating),
frequency discrimination (FD), and frequency modulation (FM)?

. Does performance on the speech-gating task mediate any relation between

auditory thresholds, phonological processing, and oral language?

M E T H O D
Participants
The sample comprised  native speakers of Cantonese Chinese aged
between ; and ;, mean ; (years;months), attending kindergarten in
Hong Kong. Fifty-seven ( male,  female) met criteria for SLI (Bishop,
; Leonard, ):
in
receptive
and hearing
screening, and demonstrated no history or
signs of neurological or
psychosocial problems. Fifty of them had already been diagnosed with SLI
when recruited from government-run Child Assessment Centers via
voluntary referral from speech pathologists. The remaining seven, recruited
from local kindergartens, were classiﬁed as SLI at the time of testing. Five

they performed below age-expected levels

language, passed cognitive

expressive

and/or



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

senior students in speech–language pathology, under the supervision of an
experienced speech–language pathologist, conﬁrmed the SLI status of these
ﬁfty-seven children using the Hong Kong Cantonese Oral Language
Assessment Scale (HKCOLAS: T’sou et al., ) – a standardized test
with local norms for diagnosing language impairments in children aged ﬁve
to twelve. These children all failed (i.e. scoring · SD below the mean)
two or more of the six subtests in the HKCOLAS, and met the other
conventional diagnostic criteria (Leonard, ). Their nonverbal IQ scores
all fell within the normal range on the Raven’s Standard Progressive Matrix
according to local age norms (Raven, , Table ).

targeting

speciﬁc

The ﬁfty-three children ( male,  female) in the language-typical control
group were recruited from kindergartens in Hong Kong. They passed a
language screening, scoring no worse than · SD below the age-normed
mean on the Cantonese Grammar and the Nominal Expressive Vocabulary
subtests of the HKCOLAS – the two subtests recommended for assessing
preschool and ﬁrst-year primary school children when under administration
time constraints (To, Cheung & T’sou, ). In the Cantonese Grammar
test, children were asked to match pictures with the sentences heard, answer
questions
and make
grammaticality judgments about complex sentences. For the Expressive
Vocabulary subtest, children were shown pictures of objects and asked to
name them. Children in the control group were also given the Narrative
Retell subtest, whereby they listened to a story and retold it to a naive
listener. Scoring was based on story content and the use of referring
expression, connectives, and complex sentences in the retell. Non-verbal IQ
scores in the control group all fell within the normal range of locally
normed Raven’s Standard Progressive Matrix scores (Raven, ).

grammatical morphemes,

All children passed a hearing screening of pure tones of ·, , , and  KHz
presented at  dB in both ears, measured using a Grason-Stadler GSI model
 calibrated audiometer. No children were reported to have otitis media
around the time of testing, or to have a diagnosis of attention deﬁcit and/or
hyperactivity disorder, or other psychosocial problems. All children spoke
Cantonese Chinese as their ﬁrst and dominant language. Descriptive and
comparative statistics for both groups are presented in Table .

Materials
Psychometric tasks

. Phonological processing

.. Phonological awareness. In a syllable-deletion task adopted from Ho,
Leung, and Cheung (), children were asked to repeat real Chinese



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

 

C
a
m
b
r
i
d
g
e
C
o
r
e
 
t
e
r
m
s
 
o
f
 
u
s
e

,
 

a
v
a

i
l

l

 

a
b
e
a
t
 
h
t
t
p
s
:
/
/

.

w
w
w
.
c
a
m
b
r
i
d
g
e
o
r
g
/
c
o
r
e
/
t
e
r
m
s
.
 

h
t
t
p
s
:
/
/
d
o

i
.

.

o
r
g
/
1
0
1
0
1
7
/
S
0
3
0
5
0
0
0
9
1
5
0
0
0
6
0
4

l

D
o
w
n
o
a
d
e
d
 
f
r
o
m
h
t
t
p
s
:
/
/

 

w
w
w
.
c
a
m
b
r
i
d
g
e
o
r
g
/
c
o
r
e

.

.
 

U
n
i
v
e
r
s
i
t
a
e
t
s
b
b

i

l
i

 

o
t
h
e
k
K
a
i
s
e
r
s
l
a
u
t
e
r
n

,
 

 

 

o
n
2
2
D
e
c
 
2
0
1
8
a
t
 
1
4
2
6
3
0

:

:

 

j

,
 
s
u
b
e
c
t
 
t
o
 
t
h
e

TA B L E . Descriptive statistics and between-group comparisons on the psychometric test results. All scores are raw scores,
except for IQ given in standard scores with a mean of  and SD of , and for oral language tests (Grammar,
Vocabulary, and Narrative) and their average (Oral lang. (avg)) given in scaled scores

Control (N = )

SLI (N = )



Age (months)
IQ
Grammar
Vocabulary
Narrative
Oral lang. (avg)
Syll. deletion (/)
NWR (/)
RAN-p (sec)

Mean

·
·
·
·
·
·
·
·
·

SD

·
·
·
·
·
·
·
·
·

Min






·


·

Max






·


·

Mean

·
·
·
·
·
·
·
·
·

SD

·
·
·
·
·
·
·
·
·

Min






·


·

Max

Comparison






·


·

F(,) = ·
F(,) = ·*
F(,) = ·*
F(,) = ·*
F(,) = ·*
F(,) = ·*
F(,) = ·*
F(,) = ·*
F(,) = ·

NOTE: * signiﬁcant at p < ·.

A
U
D
I
T
O
R
Y

P
E
R
C
E
P
T
I
O
N

A
N
D

W
O
R
D

R
E
C
O
G
N
I
T
I
O
N

I
N

S
L
I

K I D D E T A L.

words composed of three syllables each, while deleting one of its syllables
from the beginning, middle, or end of the word. An example, translated to
English, would be: ‘Please say little-fat-pig. Now say little-fat-pig again,
this time without saying fat.’ Deletion of a syllable results in either a real
word or a nonword. The maximum score for this task was .

.. Phonological short-term memory. In a non-word repetition task (Ho et al.,
), children were asked to repeat nonwords with two to six syllables.
These non-words were meaningless combinations of actual Cantonese
morphemes, with one syllable per morpheme. A child received  point for
each of the syllables correctly repeated and  point for correct ordering of
any two consecutive syllables. Points were deducted for adding syllables.
The maximum score for this task is .

.. Rapid Automatized Naming (pictures; RAN-p). Children were asked to
name ﬁve common objects (sun, apple, butterﬂy, airplane, fan) depicted by
line drawings, presented randomly in a  ×  matrix, as quickly and as
accurately as possible (Ho et al., ). Each child named them from left
to right, one row after the other. Children were asked to complete the task
twice, the score being the time taken to name the twenty drawings,
averaged across two trials.

Experimental tasks

. Frequency Discrimination (FD)
This task was modeled on that used by Hogben and colleagues (Heath,
Bishop, Hogben & Roach, ; Hill et al., ; Mengler et al., ),
and was administered with a Matlab program via headphones on a laptop
computer. In each trial, stimuli were three  ms binaural pure tones
with  ms rise/fall and  ms ISI, presented in the AXB format. The
ﬁrst tone (A) was a  Hz standard, and the third comparison tone (B)
had a frequency of  Hz plus the frequency diﬀerence for that trial.
The middle tone (X) was the same frequency as either (A) or (B), which
varied randomly across trials. Each child was to indicate, by pressing
either ‘’ or ‘’ on the keypad, which of tones A or B matched tone
X. Feedback was given via the presentation of a cartoon ‘sad’ or ‘smiley’
face on the screen.

The frequency diﬀerence between the standard and comparison tones was
varied between trials via an adaptive -up, -down staircase reversal
procedure (Wetherill & Levitt, ), which estimated the % correct
performance level. The initial frequency diﬀerence was  Hz. The initial
step-size was  Hz, which halved after each reversal until the minimum of
 Hz. The staircase lasted for eight reversals, and the Just Noticeable



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

Diﬀerence (JND) was deﬁned as the average frequency diﬀerence of the ﬁnal
four reversals. Blocks of ten practice trials were ﬁrst administered (all with a
frequency diﬀerence of  Hz) until the child achieved a criterion of at least
seven out of ten correct.

. Frequency Modulation detection (FM)
This task was modeled on that used by Heath et al. (). Stimuli were two
 Hz,  ms tones with  ms rise/fall and  ms ISI. To measure
frequency modulation detection, one tone (the standard) was unmodulated,
and the other tone (the comparison) was sinusoidally modulated at  Hz.
The presentation order of
the standard and comparison was varied
randomly across trials. The task was to indicate, by pressing ‘’ or ‘’ on
the keypad, which was the modulated tone (i.e. the tone that ‘wobbled’).

Modulation depth was varied adaptively across trials using a standard
-up, -down adaptive staircase procedure (Wetherill & Levitt, ). The
initial depth was  Hz (i.e. the frequency ranged from  Hz to  Hz).
The initial step-size was  Hz, which halved after each reversal until a
minimum of  Hz. The staircase lasted for eight reversals, with the
threshold deﬁned as the average depth of the ﬁnal four reversals. The
procedure was otherwise identical to the FD task.

. Speech-gating
This task was identical to that described by Wong et al. (a) and Kidd
et al.
(). The stimuli were sixteen frequently used Cantonese
monosyllabic nouns, ranged in length from approximately  ms to 
ms (see ‘Appendix’). They were digitally recorded at a sampling rate of
· kHz in a sound-attenuated booth by a native Cantonese-speaking
male and stored as
.wav ﬁles, which were then called into the
custom-written Matlab program for the task. Eight words were high
frequency and eight were low frequency, according to word rankings
obtained from an on-line database (an approximately , spoken word
corpus derived from spontaneous adult conversations and Hong Kong
radio programs. Information on this corpus is available from: kkluke@ntu.
edu.sg). Words were ‘high-frequency’ if they ranked above  (i.e. likely
to occur more than  times in every , spoken words), and
‘low-frequency’ if they ranked below .

Cantonese syllables, each represented orthographically by a Chinese
logograph (character), display a (Ci)Vt(Ce/G) structure, which generally
includes the lexical tone (t) and the nuclear vowel (V) as two obligatory
components, and the initial consonant (Ci), the ending consonant (Ce),
and the ending glide (G) as optional components (Bauer & Benedict,
). A few words in Cantonese, however, contain only the nasal



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

consonant ng or m and the tone (e.g. ng (ﬁve)). In this paper, Cantonese
syllables are presented in romanized forms following the scheme adopted
by the Linguistic Society of Hong Kong (). Numerals following the
syllables mark one of the nine lexical tones in the language, with each
representing a diﬀerent fundamental frequency pattern. Syllables with
tone  to  end with a vowel, a diphthong, or a nasal consonant, whereas
syllables with tone  to  end with a stop consonant /p, t/ or /k/. Tone 
is called the high-level, tone  the mid-level, and tone  the low-level
tone. Tone , , and  are the shortened version of the level tones , ,
and  respectively. Level tones have a relatively ﬂat contour where the
beginning and the
change
substantially. Tone , , and  are the contour tones, meaning that these
tones have diﬀerent starting and ending fundamental frequency values.
Tone  is the high-rise, tone  the low-fall, and tone  the low-rise tone.
The same syllable carrying diﬀerent
lexical
meanings. For example, ma refers to mother, and ma refers to horse.

tones will have diﬀerent

ending fundamental

frequency do not

The sixteen words used in this task included ten with a CVtC structure
(e.g. jan, sam, beng),  CVtG (e.g. zai, leoi), and  CV (ce and
cyu). While homophones exist for some of these target words (e.g. the
very low frequency 仁 ‘kindness’ jan is a homophone variant of the target
word 人 ‘man’ jan), eﬀort was made to ensure that all homophones of the
target words were extremely low in frequency (i.e. below  in ,).

Neighborhood density was estimated for each word by hand because no
published database detailing such information was available in Cantonese.
We used traditional deﬁnitions of neighborhood density (i.e. the number
of words that overlap with the target word by substituting the onset,
nucleus, or ﬁnal phonemes (Charles-Luce & Luce, ), and we added
lexical tone to this list because Cantonese-Chinese is a tonal language.
Estimates ranged from  (low-density) to  (high-density); delineation of
‘high’ and ‘low’ was based on a median split across the sixteen words.

The task was administered with custom-written Matlab (Version .)
software on an IBM Thinkpad laptop via headphones with a microphone
attachment. A forward-gating, duration-blocked procedure was adopted
(Griﬃths & Snowling, ; Grosjean, ). The ﬁrst block presented
the initial gate for each of the sixteen words in random order. The second
block presented the previous gate PLUS ONE GATE for all sixteen words,
again in random order. Successive blocks added another gate such that
words were presented in accumulating increments until all sixteen words
had been presented in their entirety. Because words diﬀered from one
another in length, they each required a diﬀerent number of gates. Thus,
blocks had a reducing set of target stimuli. As in previous studies (Kidd
et al., ; Wong et al., a), we used an initial gate length of  ms
and a subsequent gate length of  ms. The proportion of the target word



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

presented over the initial gate varied from · for the longest stimulus to ·
for the shortest (see ‘Appendix’).

Designed to be a child-friendly computer game, each trial showed a
picture of aliens on the screen. A child would ﬁrst be told that aliens were
attempting to learn our language; the child was to listen to each word
segment and repeat the word the alien was trying to say. The experimenter
initiated each trial via a button press; the speech segment was presented
 ms thereafter. The picture remained on the screen for the entire trial.
The child was given a maximum of  s after the speech segment had
ended to verbally identify the target word. The next trial was initiated
once the child had ﬁnished speaking, which rarely required the full  s.
Children’s responses were recorded directly on the computer’s hard disk
for
trials using high-frequency
monosyllabic concrete nouns, no rest interval between blocks and no
feedback was given. Administration time was about  minutes. Upon
completion, the experimenter showed images of each noun and asked the
child to name it. This conﬁrmed children’s familiarity with the target words.

coding. After

later

two practice

General procedure
This research was approved by The Human Research Ethics Committee at
the University of Hong Kong. Written informed consent was obtained
from all parents/guardians prior to participation. Children also gave verbal
assent at the time of testing.

Children were tested in a university laboratory, their kindergarten, or the
Child Assessment Centre they attended. As noted earlier, we used the
HKCOLAS to conﬁrm the ﬁfty-seven children’s SLI status. Two research
assistants administered three HKCOLAS subtests (Cantonese Grammar,
Nominal Expressive Vocabulary, Narrative Retell) to the control group,
and all other tasks (i.e.
the FD, FM, and
speech-gating tasks) to the full sample. Testing took about  hours per
child, spread over two or three days: hearing screening, Raven’s, and
HKCOLAS,
tasks.
Parents/guardians received modest cash compensation for participation
time and transportation costs to the university.

then the remaining cognitive and experimental

the psychometric tasks,

R E S U L T S
Raw scores from the Raven’s test were converted to age-normed standard
scores with a mean of  and a standard deviation of , and scores on
the HKCOLAS were converted to scaled scores (Table ). The three oral
language subtests of the HKCOLAS correlated highly (Table ) and were
therefore combined into one composite score (mean z-score). Descriptive
and comparative statistics for the SLI group and the control group are



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

 

C
a
m
b
r
i
d
g
e
C
o
r
e
 
t
e
r
m
s
 
o
f
 
u
s
e

,
 

a
v
a

i
l

l

 

a
b
e
a
t
 
h
t
t
p
s
:
/
/

.

w
w
w
.
c
a
m
b
r
i
d
g
e
o
r
g
/
c
o
r
e
/
t
e
r
m
s
.
 

h
t
t
p
s
:
/
/
d
o

i
.

.

o
r
g
/
1
0
1
0
1
7
/
S
0
3
0
5
0
0
0
9
1
5
0
0
0
6
0
4

l

D
o
w
n
o
a
d
e
d
 
f
r
o
m
h
t
t
p
s
:
/
/

 

w
w
w
.
c
a
m
b
r
i
d
g
e
o
r
g
/
c
o
r
e

.

.
 

U
n
i
v
e
r
s
i
t
a
e
t
s
b
b

i

l
i

 

o
t
h
e
k
K
a
i
s
e
r
s
l
a
u
t
e
r
n

,
 

 

 

o
n
2
2
D
e
c
 
2
0
1
8
a
t
 
1
4
2
6
3
0

:

:

 

j

,
 
s
u
b
e
c
t
 
t
o
 
t
h
e




TA B L E . Pearson correlations among oral language, phonological processing, reading, speech-gating, and auditory measures (* p
< ·; ** p < ·; *** p < ·). HF-HD = High-Frequency High-Density; HF-LD = High-Frequency Low-Density; LF-HD =
Low-Frequency High-Density; LF-LD = Low-Frequency Low-Density; IP = Isolation Point, the mean number of gates required to
ﬁrst identify the target word correctly; AP = Acceptance Point, the mean number of gates required to correctly identify the target
word without subsequent change of response





































IQ

 Oral lang.

 Age
 Non-verbal

−·*
−·
−·
 Grammar
 Vocabulary −·
−·
 Narrative
·
 Syllable

(avg)

deletion
 Nonword

rep.

·***

·***
·**
·***
·***

·***
·***
·***
·***

·***
·***
·***

·***
·***

·***

 RAN-pics
 HF-HD IP
 HF-HD AP
 HF-LD IP
 HF-LD AP
 LF-HD IP
 LF-HD AP
 LF-LD IP
 LF-LD AP
 FD
 Log FM

·**

·***

·***

·***

·***

–·
·***
−· −·
−·** −·* −·* −·** −·** −·
−· −·
−·*
−·** −·** −·** −·* −·
·
· −·
−·** −·
−·** −·** −·** −·* −·
−· −·
−· −·**
−·
−·
−·
·
−· −·
−· −·
−·
−·
−·
·
−·* −·
−·
−·
−·
−·
·
·
· −·
−·* −·* −·
−·
−·
−· −·
−· −·
−·*
−·
−·* −·
−·
·
−·**
−·
−·
−·
−·
−·
·
·
· −·
· −·** −·* −·* −·* −·
−·* −·
· −·* −·*** −·** −·*** −·** −·* −·*
·**
·

·
−·
−·
−·
−·

·***
·**
·***
·**
·**
·***
·**

·
·***
·*
·***
·***
·***
−·
·

·***
·
·
·**
·
·
−·

·
·**
·***
·***
·
−·

·***
·
·
−·
−·

·
·***
·**
·
·
· −·

−·
−· ·***

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

presented in Table . Signiﬁcant diﬀerences on the oral language subtests
reﬂected the diagnostic criteria and conﬁrmed the group assignment (with
versus without SLI). There was no signiﬁcant diﬀerence in age between
groups. As expected, the SLI group performed signiﬁcantly worse than
the control group in phonological awareness and non-word repetition. For
non-verbal IQ, one child in each group scored below ; however, their
scores (both ) were still within the average range under the classiﬁcation
of the test (Raven, ), and thus were not excluded from the study.
Group means were both over , but the mean non-verbal IQ was
signiﬁcantly lower in the SLI group. We therefore statistically controlled
for non-verbal IQ in data analyses wherever feasible.

Poorer auditory thresholds in SLI?
Thresholds for both auditory tasks were checked for outliers: none converted
to z > · (corresponding to p < ·, two-tailed), therefore none were
removed. For the staircase tracks in both tasks, all but one child (from the
SLI group on the FM task) showed an acceptable ‘ﬂattening’ around the
that child’s threshold and associated
threshold following adaptation;
auditory data were excluded from further analysis. Table  and Figure 
present the descriptive statistics and threshold distributions, respectively.
Thresholds from the FM and FD tasks were signiﬁcantly related (r = ·,
p < ·), suggesting some degree of concurrent validity (Heath et al., ).
Signiﬁcant skewness for the FM thresholds was observed in the SLI group
(skewness = ·, SE = ·), although not the control group (skewness = ·,
SE = ·), therefore requiring log transformation. Skewness in the FD data
was not signiﬁcant for either group. ANCOVA revealed that children with
SLI performed less well
(i.e. had higher thresholds) on both tasks,
signiﬁcantly so for logFM even after controlling for age and non-verbal
IQ (F[,] = ·, p = ·, ηp
 = ·), but not for FD (F[,] = ·,
p > ·, η = ·).

The standard deviation was greatest in the SLI group (Figure ); 
children with SLI had a logFM threshold greater than the maximum of the
language-typical control group. This is a classic ﬁnding in psychophysical
experimentation in clinical groups (Roach, Edwards & Hogben, ). Do
these  children represent a discrete subgroup? The data given in Table 
suggest not. This subgroup diﬀered signiﬁcantly from the remaining 
children with SLI only in FD thresholds and not on other key variables
examined.

Poorer spoken word recognition in SLI?
Verbal responses to the target words of the speech-gating task were coded by
two trained coders. Inter-rater reliability was good,
indicated by high



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

TA B L E . Descriptive statistics by group for frequency modulation (FM) and

K I D D E T A L.

frequency discrimination (FD)

Control

SLI

N Mean Mdn SD Min Max N Mean Mdn SD Min Max

·

·

FM (Hz) 
FD (Hz)

·

·
 · · · · ·  · · · · ·

·  · ·

·

· ·

Fig. . Distributions of thresholds for FM (left) and FD (right) arranged by group.
Horizontal lines indicate group means; error bars indicate standard error of the mean.
Datapoints are arranged along the abscissa to avoid overlap.

intra-class correlations (R = · and · for IP and AP, respectively).
Children’s audio-recorded responses were coded as correct or incorrect at
each gate for each target word, thus we identiﬁed the gate at which the
child ﬁrst correctly identiﬁed the target word (the ‘Isolation Point’: IP),
and correctly identiﬁed the word without subsequently changing that
response (the ‘Acceptance Point’: AP). Both IP and AP were expressed as
the mean number of gates required for correct word identiﬁcation.



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

 

C
a
m
b
r
i
d
g
e
C
o
r
e
 
t
e
r
m
s
 
o
f
 
u
s
e

,
 

a
v
a

i
l

l

 

a
b
e
a
t
 
h
t
t
p
s
:
/
/

.

w
w
w
.
c
a
m
b
r
i
d
g
e
o
r
g
/
c
o
r
e
/
t
e
r
m
s
.
 

h
t
t
p
s
:
/
/
d
o

i
.

.

o
r
g
/
1
0
1
0
1
7
/
S
0
3
0
5
0
0
0
9
1
5
0
0
0
6
0
4

l

D
o
w
n
o
a
d
e
d
 
f
r
o
m
h
t
t
p
s
:
/
/

 

w
w
w
.
c
a
m
b
r
i
d
g
e
o
r
g
/
c
o
r
e

.

.
 

U
n
i
v
e
r
s
i
t
a
e
t
s
b
b

i

l
i

 

o
t
h
e
k
K
a
i
s
e
r
s
l
a
u
t
e
r
n

,
 

 

 

o
n
2
2
D
e
c
 
2
0
1
8
a
t
 
1
4
2
6
3
0

:

:

 

j

,
 
s
u
b
e
c
t
 
t
o
 
t
h
e

TA B L E . Descriptive and comparative statistics for the subdivided SLI group (above and below the maximum logFM

threshold of the control group) on key auditory and psychometric variables (* p < ·; ** p < ·)

logFM > · (N = )

logFM < · (N = )




logFM
FD (Hz)
Age (months)
IQ
Grammar
Vocabulary
Narrative
Oral lang. (avg)
Syll. deletion (/)
NWR (/)
RAN pics (sec)

Mean

·
·
·
·
·
·
·
·
·
·
·

SD

·
·
·
·
·
·
·
·
·
·
·

Min

·
·
·
·
·
·
·
·
·
·
·

Max

·
·
·
·
·
·
·
·
·
·
·

Mean

·
·
·
·
·
·
·
·
·
·
·

SD

·
·
·
·
·
·
·
·
·
·
·

Min

·
·
·
·
·
·
·
·
·
·
·

Max

·
·
·
·
·
·
·
·
·
·
·

Comparison

F(,) = ·**
F(,) = ·*
F(,) = ·
F(,) = ·
F(,) = ·
F(,) = ·
F(,) = ·
F(,) = ·
F(,) = ·
F(,) = ·
F(,) = ·

A
U
D
I
T
O
R
Y

P
E
R
C
E
P
T
I
O
N

A
N
D

W
O
R
D

R
E
C
O
G
N
I
T
I
O
N

I
N

S
L
I

K I D D E T A L.

TA B L E . Descriptive statistics
for the speech-gating task (HF = High
Frequency; LF = Low Frequency; HD = High Density; LD = Low Density;
IP = Isolation Point, the mean number of gates required to ﬁrst identify the
target word correctly; AP = Acceptance Point, the mean number of gates
required to correctly identify the target word without subsequent change of
response)

Word type

HF

LF

HD

LD

HF-HD

HF-LD

LF-HD

LF-LD

IP
AP
IP
AP
IP
AP
IP
AP
IP
AP
IP
AP
IP
AP
IP
AP

All participants
(N = )
Mean (SD)

Control
(N = )
Mean (SD)

SLI
(N = )
Mean (SD)

· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)

· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)

· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)
· (·)

low-neighborhood-density (LD)

The results are presented in Table  and Figure . Ceiling eﬀects were not
observed for any word type (Figure ). Consistent with Metsala (),
children needed to hear more gates for low-frequency (LF) words than
high-frequency (HF) words to both recognize and accept them, likewise
for
than high-neighborhood-density
(HD) words. To examine the eﬀects of word frequency and neighborhood
density on spoken word recognition, IP and AP for HF, LF, HD, and LD
words were compared using repeated measures ANOVA, with word type
as the within-subject
factor, and group (SLI versus control) as the
between-subject
factor, controlling for age and non-verbal IQ. Main
eﬀects were signiﬁcant for word type (F[,] = ·, p < ·, η = ·),
for group (F[,] = ·, p = ·, η = ·), and no
and marginal
signiﬁcant interaction was found between word type and group (F[,] =
·, p = ·, η = ·). Post-hoc analyses (Tukey’s HSD ps < ·) revealed,
as predicted: (i) the IP occurred at a signiﬁcantly earlier point in the word
than the AP for all word types; (ii) signiﬁcantly earlier IP and AP (i.e.
fewer gates) for high-frequency words than low-frequency words; and (iii)
signiﬁcantly earlier IP and AP for high-density words than low-density
words. To examine whether some word types took less time to accept than



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

Fig. . Distributions of results on the speech-gating task for the control group (triangles)

and the SLI group (circles) for each word type.

all below 

for

and kurtosis were

others following their initial recognition, the diﬀerence between the IP and
AP was calculated by word type for all participants. Absolute values of
these diﬀerences.
skewness
Repeated-measures ANOVA, with age and IQ as covariates,
indicated
a marginally signiﬁcant eﬀect of word type in these diﬀerence scores
(F[,] = ·, p = ·, η = ·). Tukey post-hoc comparisons revealed no
signiﬁcant diﬀerence for high- versus low-frequency words. But there was a
signiﬁcant neighborhood density eﬀect: children required fewer gates to
commit to a word after ﬁrst identifying the word if it came from a high-
rather than low-density neighborhood (p < ·).



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

Considering the pattern of results separately for each group, the main
eﬀect of word type was signiﬁcant for the SLI (F[,] = ·, p < ·,
η = ·) but not for the control group (F[,] = ·, p = ·, η = ·).
Among children with SLI, word recognition times indicated by IP and
AP were both shorter for high- than low-frequency words, and for high-
than low-density words (ps < ·).

We further categorized the word stimuli

interact

 = ·; AP: F[,] = ·, p = ·, ηp

For all word types, children with SLI on average needed to hear more of
the target words than controls (Table ). This diﬀerence was signiﬁcant for
high-density words after controlling for age and non-verbal IQ (IP:
F[,] = ·, p = ·, ηp
 = ·),
but not for low-density words (IP: F[,] = ·, p = ·; AP: F[,] =
·, p = ·). Group diﬀerences were not found for either high-frequency
(IP: F[,] = ·, p = ·; AP: F[,] = ·, p = ·) or low-frequency
words (IP: F[,] = ·, p = ·; AP: F[,] = ·, p = ·). These
results
suggested that children with SLI needed to hear a greater
proportion of high-density words than language-typical controls in order to
identify and accept a target word, perhaps reﬂecting less restructuring for
the phonological
representations despite the considerable pressure to
diﬀerentiate. There was, however, no signiﬁcant diﬀerence between groups
in the time between ﬁrst identifying the word and then committing to it (i.e.
the diﬀerence between IP and AP) for any word type (Fs[,] < ·, ps > ·).
into four mutually exclusive
groups (high-frequency high-density (HF-HD), high-frequency low-density
(HF-LD), low-frequency high-density (LF-HD), low-frequency low-density
(LF-LD); Table ) to take a tentative look at how word frequency and
neighborhood density might
to aﬀect word recognition. No
signiﬁcant diﬀerences were observed among the four word categories in either
word length (F[,] = ·, p > ·) or the proportion of word presented in
the initial gate (F[,] = ·, p > ·). We performed two separate ANOVAs
(one for IP, and one for AP), with group (SLI versus control) as the
between-subject factor, and word category (HF-HD, HF-LD, LF-HD,
LF-LD) as the within-subject factor, while controlling for age and IQ. There
was a signiﬁcant main eﬀect of word category for AP (F[,] = ·, p
= ·, η = ·) but not IP (F[,] = ·, p = ·, η = ·), and post-hoc
comparisons (Tukey’s HSD ps < ·) revealed that the earliest AP occurred
for the HF-HD words, followed by the LF-HD words, for which word
recognition occurred slightly faster than the HF-LD stimuli. The poorest
recognition was on the LF-LD words, which the lexical restructuring
hypothesis would predict as under the least developmental pressure to
diﬀerentiate (Fowler, ; Metsala & Walley, ). By contrast, the main
eﬀects of group (SLI versus control) were not found to be signiﬁcant for IP
and AP (Fs[,] < ·, ps > ·), nor were the interaction eﬀects between
word category and group (Fs[,] < ·, ps > ·).



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

Does spoken word recognition mediate between auditory perception, phonological
processing, and oral language?
Two-tailed Pearson correlations were calculated among all psychometric,
auditory, and speech-gating measures
(Table ). LogFM correlated
signiﬁcantly with all oral language and phonological processing measures,
but did not correlate with any of the speech-gating variables.

To test

auditory perception,

for the potential mediation relations among spoken word
recognition,
and phonological processing, path
analyses were conducted using structural equation modeling. Three
competing models were tested, and each model showed one of the three
latent variables
(word recognition, phonological processing, auditory
perception) as a mediator between the other two (Figure , Models –).
In all the models, the auditory perception latent variable was indicated by
FD thresholds and logFM, while the phonological processing latent
variable was indicated by syllable deletion, non-word repetition, and
RAN. IPs of
the four word categories (HF-HD, HF-LD, LF-HD,
LF-LD) from the speech-gating task were used to tap the latent variable
of word recognition. Age and IQ were entered as covariates in all the
analyses to partial out their eﬀects. Standardized path coeﬃcients are given
in Figure .

Goodness of ﬁt of the models to the data was evaluated by comparing four
ﬁt indices, including chi-square statistic, Bentler’s () comparative ﬁt
index (CFI), Bollen’s () incremental ﬁt index (IFI), and the root
mean square error of approximation (RMSEA). A signiﬁcant chi-square
(p < ·) indicates that the observed covariance matrix signiﬁcantly deviates
from the covariance matrix implied by the model, and hence suggests poor
model ﬁt. Unlike chi-square, which compares a model with the observed
data, both CFI and IFI reﬂect the relative goodness-of-ﬁt by comparing
the ﬁt of a hypothesized model to the ﬁt of a null model. These indices
range from · to ·, with larger values denoting better model ﬁt.
According to the cut-oﬀ criteria proposed by Hu and Bentler (),
values close to · and above indicate relatively good ﬁt. RMSEA provides
an estimate of the discrepancy in ﬁt per degrees of freedom, and values
below · are generally considered as close ﬁt, while values ranging from
· to · are accepted as adequate ﬁt (Kline, ). The p of close ﬁt
(PCLOSE) is a one-sided test of the hypothesis that RMSEA is equal to
·. A signiﬁcant p value indicates that the model ﬁt is worse than close
ﬁtting (i.e. RMSEA is signiﬁcantly larger than ·). Akaike information
criterion (AIC) and Browne–Cudeck criterion (BCC) were also considered
to further compare the models. They are likelihood-based measures of
model ﬁt
the complexity of models. When
comparing AIC and BCC for multiple models, the smaller the value of the

take into account

that



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

relationship between auditory perception, word recognition,

Fig. . Structural equation models (Model , TOP; Model , MIDDLE; Model , BOTTOM) on
the
and phonological
processing. Standardized regression coeﬃcients and squared multiple correlations (in
brackets) are shown (* p < ·; ** p < ·; *** p < ·).



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

TA B L E . Goodness-of-ﬁt indices of structural equation models depicted in

Figures  and 

Model








df








χ

·
·
·
·
·
·

p

·
·
·
·
·
·

CFI

IFI RMSEA %CI PCLOSE AIC

BCC

·
·
·
·
·
·

·
·
·
·
·
·

·
·
·
·
·
·

·–·
·–·
·–·
·–·
·–·
·–·

·
·
·
·
·
·

·
·
·
·
·
·

·
·
·
·
·
·

NOTES: df = degrees of freedom; χ = model chi-square; CFI = comparative ﬁt index; IFI =
incremental ﬁt index; RMSEA = root mean square error of approximation; CI = conﬁdence
interval; PCLOSE = p value of close ﬁt; AIC = Akaike information criterion; BCC =
Browne–Cudeck criterion.

criterion, the better is the model ﬁt to the data. Fit indices for the models are
listed in Table .

Results of the path analyses on Models  to  (Figure ) showed that: (i)
auditory perception was signiﬁcantly related to phonological processing
abilities even after controlling for word recognition, age, and IQ; (ii)
auditory perception did not predict spoken word recognition; and (iii)
spoken word recognition was not signiﬁcantly related to phonological
processing. Fit
revealed that Model , with phonological
processing predicting both auditory perception and word recognition,
provided a better ﬁt to our data than Models  and , though none of
these models showed values of CFI and IFI higher than ·. These results
argue against a possible mediating eﬀect of spoken word recognition
between auditory perception and phonological processing.

indices

Analogous models (Figure , Models –) were tested with oral language
speciﬁed by the three subtests (Grammar, Expressive Vocabulary, and
Narrative-retell). Fit indices for all three models indicated relatively good
ﬁt to the data, and both AIC and BCC were slightly lower for Model  as
compared to Models  and  (Table ). Spoken word recognition was a
signiﬁcant predictor of oral language in Model , but auditory perception
did not predict either word recognition or oral language, and no mediating
eﬀect was found. When the direction of prediction was reversed, oral
language signiﬁcantly predicted both word recognition and auditory
perception (Model ).

D I S C U S S I O N
This study compared SLI and age-matched controls on speech-gating,
frequency modulation (FM) detection, and frequency discrimination (FD).



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

Fig. . Structural equation models (Model , TOP; Model , MIDDLE; Model , BOTTOM) on
the relationship between auditory perception, word recognition, and oral
language.
Standardized regression coeﬃcients and squared multiple correlations (in brackets) are
shown (* p < ·; ** p < ·; *** p < ·).



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

We examined whether SLI is characterized by poorer overall performance
on the FD, FM, or speech-gating tasks, and whether spoken word
recognition – as measured by speech-gating – mediates the relation between
auditory perception and phonological processing.

are

smaller

Speech-gating
Between-group comparisons in speech-gating yielded several new ﬁndings.
First, spoken word recognition developed in the SLI children according to
similar pressure constraints as in typically developing children. Children with
SLI demonstrated more expedient word recognition for high-
than
low-frequency words, and for high- than low-density words. It therefore
appears that the basic process of spoken word recognition does not diﬀer
markedly between children with and without SLI. These ﬁndings are in line
with ﬁndings on another clinical group, namely late talkers. Although
late-talking toddlers’ productive vocabularies
than their
age-matched peers’, they tend to produce words with high rather than low
neighborhood density – just like their language-matched controls (Stokes, ).
The key ﬁnding from speech-gating was that, as a group, children with SLI
needed to hear signiﬁcantly larger portions of high-neighborhood-density
words than language-typical controls to both initially identify them, and
identify them without subsequent change of mind. How might poorer word
recognition for high-density words in SLI be explained? We tried to rule out
obvious candidates. Recall
to
language-typical controls in how much their word recognition was facilitated
by word frequency and neighborhood density. Also, while they diﬀered for
high-density words, they did not diﬀer for high-frequency, low-frequency,
and low-density words. So, a general account such as smaller vocabulary size
or language exposure probably cannot explain the diﬀerence between SLI
and language-typical controls in their recognition of high-density words
(Metsala & Walley, ). The ability to predict the target words using
coarticulation cues or tonal information likewise cannot explain the group
diﬀerence only for high-density words. That is, if children with SLI were
unable to take advantage of any coarticulation cues or tonal information
evident across gates, we might expect such diﬃculty to exist for all word
types, rather than just the high-density words.

that children with SLI were similar

McMurray et al. () suggested that higher levels of lexical decay in SLI
might prevent full activation of the phonological representation, leaving it
vulnerable to active competitors. In this study, both SLI and language-typical
children needed signiﬁcantly fewer gates to commit to a word after ﬁrst
identifying it if the word came from a high- rather than low-density
neighborhood. At the same time, children with SLI needed to hear larger
fragments of high-density words to both initially recognize and subsequently



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

accept them without change of mind, when compared to language-typical
children. However, no group diﬀerences were found in the length of time
between ﬁrst recognizing a word, and then committing to that word, for any
word type. This pattern of result suggests that the group diﬀerence observed
here in spoken word recognition for high-density words cannot be due to
greater vacillation between lexical entries – as might be expected if initial
lexical activation were more vulnerable to active competitors in SLI.

Collectively, these results, whether pooled across all participants or taken
from within each group, are consistent with the lexical restructuring
hypothesis, which predicts greater diﬀerentiation for high- over low-
frequency words, as well as for high- over low-neighborhood-density
words. We found that high-frequency words were recognized and accepted
after fewer gates than low-frequency words, and the same was found for
high-density words in contrast to low-density words. When categorized by
both word frequency and neighborhood density, high-frequency–high-
density words required the fewest gates for recognition, while low-
frequency–low-density words required the most. Our results also indicated
that high-density words were accepted after their initial recognition much
more quickly than low-density words, suggesting that an eﬃcient storage
and retrieval system emerges from lexical restructuring where there is keen
phonological competition among items.

In light of this framework, then, the present results point to three main
conclusions about the underlying lexical organization in SLI: (i) phonological
representations do indeed undergo development (conceptualized as lexical
restructuring for better word diﬀerentiation)
in SLI, as they do in
language-typical children; (ii) development of phonological representations
occurs according to the same word-related pressures in children with SLI as
in typically developing children; but (iii) the process is more protracted for
high-density words in children with SLI, as suggested by Wong et al.
(a). So, children with SLI perhaps
in
representations – more
developmentally restructuring their phonological
speciﬁcally, in responding to the developmental pressure due to extensive
overlap among phonologically similar words
lexical
representations.
This account

ties in well with previous ﬁndings of word-ﬁnding
diﬃculties such as poorer nonword repetition and subpar naming in SLI.
The processes that enable a child to expediently access and make use of
phonological representations, then, may well depend on the types of
words – or more precisely, on how well established the representations are.
This account also ﬁts well with previous investigations of the quality of
phonological representations in SLI via tasks other than speech-gating.
Notably, Claessen and Leitão () and Claessen et al. () used a
receptive task, asking children to either accept or reject, as a correct

lag behind their peers

to reﬁne

their



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

production, a range of correctly or incorrectly pronounced polysyllable
words. Their studies revealed that children with SLI performed less well
than both age- and language-matched controls – being less likely to reject
an incorrectly produced word – indicating less well-speciﬁed underlying
phonological representations. The present results converge with these
ﬁndings to suggest that the representation of phonological information is
subpar in SLI.

The restructuring hypothesis for phonological representations was ﬁrst
formulated using data from languages with alphabetic orthographies,
where morphemes are mapped onto phonemes or phoneme strings. Our
ﬁndings from a Cantonese-Chinese-speaking sample also lend support to
this major hypothesis, in a language (i.e. Chinese) where morphemes are
that the
consistently mapped on to syllables. These ﬁndings suggest
responds
development of phonological
representations
same
developmental pressures across very diﬀerent
languages. Longitudinal
follow-ups are needed to better understand whether and how restructuring
of phonological representations changes as a function of age in SLI. These
studies need to focus on whether the lag constitutes a developmental delay
that will remain or perhaps ameliorate with age and further exposure to
oral
language and reading, or whether children with SLI eventually
outgrow this developmental lag/deﬁcit.

to the

Auditory perception
As a group, children with SLI were less able to detect FM than their
language-typical counterparts. The thresholds of most children with SLI
were above the control group mean, and a good number of them were
even above the control group maximum. Furthermore,
the relations
between logFM thresholds and phonological processing and oral language
were negative and signiﬁcant. These ﬁndings potentially point to some
kind of auditory impairment in at least some children with SLI. However,
while FD correlated somewhat with measures of oral
language and
phonological processing in our study, overall poorer FD did not seem to
characterize SLI, in contrast to Mengler et al.,’s () ﬁndings.

Intriguingly, a group diﬀerence was found here for FM but not FD, even
though FM correlated with FD. Prior research recommended focusing on the
developmental trajectory of individual psychophysical task performance
(McArthur & Bishop, ). Thresholds and performance variability on
tasks such as these seem to improve with age (Wightman, Allen, Dolan,
Kistler & Jamieson, ). Critically, the developmental trajectory can be
more or less protracted depending on the task. For kindergarteners, for
example, a diﬀerence in FM between children with and without SLI can
be detected perhaps because FM development is advanced enough for the



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

two groups of children to diverge, whereas diﬀerences in FD attributable to
SLI might remain obscured because of immaturity in this aspect of
development. Consistent with this, the AXB paradigm is purportedly a
cognitively complex task (Wong et al., a) even though it has proved to
be more appropriate for use in children than a two-alternative forced choice
paradigm (Sutcliﬀe & Bishop, ), despite the latter’s advantage of
reducing short-term memory demands and removing linguistic labeling of
stimuli (Mengler et al., ). It might simply be that FM is easier for
young children to understand because modulation in frequency may be
more salient than mere diﬀerences in frequency. This may well turn out to
help make sense of the correlations between FD, phonological processing,
and oral language, in the absence of any group diﬀerences for FD between
the SLI and language-typical groups.

frequency modulations is crucial

Alternatively, the ﬁndings on FM and FD might be speciﬁc to tonal
languages. Cantonese Chinese, like all Chinese dialects, is a tonal language
and detection of
for distinguishing
diﬀerent
that span individual
syllables. Deﬁcits in FM perception may be especially detrimental to oral
language development in tonal languages. Future work should examine
whether, and how, deﬁcits in lower-level auditory perception aﬀect lexical
and higher-level language processing in tonal languages.

falling)

lexical

tones (e.g.

level, rising,

Relations between tasks
Despite poorer sensitivity to FM in SLI, and overall poorer speech-gating
performance for words in high-density neighborhoods, these two deﬁcits
did not seem to be directly connected. Auditory thresholds did not
correlate with any measure of the speech-gating task, and path analyses
indicated that word recognition, as indexed by this task, does not mediate
between auditory perception and phonological processing skills. Sensitivity
to FM and FD seems therefore to have little impact on spoken word
recognition. These results are therefore contrary to the long-standing
suggestion that auditory perceptual diﬃculties, of the type implicated by
poorer than average FM and FD, disrupt the development of phonological
representations (Benasich & Tallal, ).

It is entirely possible that previous discussions (e.g. Benasich & Tallal,
) have incorrectly construed the relations among auditory processing,
quality of phonological representations, and further cognitive skills (e.g.
phonological processing).
in the quality of
phonological representations might turn out to be most inﬂuenced by
cognitive factors such as working memory, rather than sensory processing.
That is, auditory perception might have no direct impact on the ongoing
development of phonological representations beyond some basic level of

Individual diﬀerences



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

auditory processing. Other cognitive factors might cause some children with
SLI to perform poorly on auditory tasks, without that performance being
directly linked to a phonological representations problem (Halliday &
Bishop, ; McArthur & Bishop, ; Rosen, ). Such an
interpretation would argue against speciﬁc lower-level auditory perception
deﬁcits as an account of SLI.

language abilities,

Using eye-ﬁxations during a categorical perception-cum-spoken word
picture matching task, McMurray, Munson, and Tomblin () found
that adolescents with a range of
including those
diagnosed with SLI, showed a similar gradient eﬀect of voice onset time
and mapped this perceptual cue onto phonological categories in a similar
fashion. The adolescents with SLI, however,
looked at the competing
word longer,
lexical
representations. In our study, by analogy, children’s performance in the
speech-gating task could have been undermined by words competing for
recognition rather than by subpar quality of phonological representations.
While children with SLI may have an auditory perception deﬁcit, such a
deﬁcit may not aﬀect lexical and higher-level language processing.

suggesting trouble in suppressing activation of

On the other hand, auditory perception might indeed be related to
phonological processing via phonological representations, but the tasks used
in the present study did not adequately capture these relations. Diﬀerent
tasks likely reﬂect diﬀerent aspects of phonological representations – how
easily new representations are formed, how accessible they are, and how
precise they are as reﬂected through articulation or speech perception
(Anthony, Williams, Aghara, Dunkelberger, Novak & Mukherjee, ).
Probably no single task encompasses all of these; speech-gating mainly
reﬂects accessibility and precision. Could it be that speech-gating reﬂects
simple guessing from a cohort of words generated based on input at each
gate, rather than diﬀerentiation of the phonological representations per se?
Our items analysis of word type, albeit exploratory, seems to argue against
this possibility. Better spoken-word recognition (i.e. recognition based on
the fewest gates) occurred for high-frequency high-density words – words
for which the greatest cohort of lexical entries would be generated, making
guessing the
the poorest
recognition was for low-frequency low-density words – words with only a
small cohort of possible items that could be generated in the children’s
lexicons. If the speech-gating task simply reﬂects the ability to guess about
a limited range of options, rather than how well the representation has been
honed by neighborhood density, we would expect spoken word recognition
to take the most time for words in a high-density neighborhood because of
the many phonological similar options. Yet, our results were exactly the
opposite,
the speech-gating task indeed taps
organization at the level of the phonological representations itself. In future

correct word much harder. Conversely,

suggesting instead that



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

representations. Furthermore,

studies, speech-gating should be augmented with further measures of
phonological
study examined only
auditory tasks with a frequency component; a more comprehensive test
battery including tasks that relate to phonological processing abilities might
be more informative.

this

We note a limitation of our speech-gating task: tonal information may
facilitate recognition of word fragments by slowing access to competitors
with similar segmental information (Sereno & Lee, ). Given ﬁndings
from diﬀerent experimental tasks that Cantonese lexical tones vary in their
ease of identiﬁcation (Ching, ; Ciocca & Lui, ; Wong et al.,
), a potential concern here is that certain lexical tones have a greater
facilitatory eﬀect than others – a concern that is not fully accounted for in
our neighborhood density measures. We suggest that control for closeness
of lexical tone be considered for future use of this task in tonal languages,
particularly where the facilitating inﬂuences on recognition of word
fragments are considered.

S U M M A R Y A N D C O N C L U S I O N S
study investigated the relations between frequency modulation
This
detection and frequency discrimination (i.e.
auditory perception),
speech-gating (i.e. spoken word recognition), and phonological processing,
in kindergarteners with and without SLI. Even in a strongly syllabic
language such as Cantonese Chinese (where morphemes consistently map
onto syllables) the phonological representations of children with SLI
appear to develop according to the same developmental pressures of word
frequency and neighborhood density as in alphabetic languages – where
morphemes map onto phonemes as well as phoneme strings – and as in
language-typical children. However, children with SLI appear to lag
behind their
they can correctly
recognize high-neighborhood-density words. The lexical restructuring
model posits
and accurate word recognition for
high-neighborhood-density words
the
phonological representations more distinct from their acoustically similar
neighbors. Delay in recognizing high-neighborhood-density spoken words,
then,
restructuring of phonological
representations.

language-typical peers

could reﬂect

a

lag in lexical

that

expedient

in how fast

is

achieved

by

rendering

Further, the auditory perceptual thresholds of children with SLI seem to
be signiﬁcantly worse than those of language-typical children for frequency
modulation detection. However, while FM thresholds,
speech-gating
performance, and phonological processing were evident
in SLI, no
mediating relation was found.



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

R E F E R E N C E S

Allopenna, P. D., Magnuson, J. S. & Tanenhaus, M. K. (). Tracking the time course of
spoken word recognition using eye movements: evidence for continuous mapping models.
Journal of Memory and Language , –.

Anthony, J. L., Williams, J. M., Aghara, R. G., Dunkelberger, M., Novak, B. & Mukherjee,
A. D. (). Assessment of individual diﬀerences in phonological representation. Reading
& Writing , –.

Bailey, P. J. & Snowling, M. J. (). Auditory processing and the development of language

and literacy. British Medical Bulletin , –.

Bauer, R. S. & Benedict, P. K. (). Modern Cantonese phonology. Berlin: Mouton de

Benasich, A. A. & Tallal, P. (). Infant discrimination of rapid auditory cues predicts later

language impairment. Behavioral Brain Research , –.

Bentler, P. M. (). Comparative ﬁt indexes in structural models. Psychological Bulletin

Gruyter.

, –.

Bishop, D. V. M. (). Uncommon understanding: development and disorder in language

comprehension in children. Hove: Psychology Press.

Bishop, D. V. M., Carlyon, R. P., Deeks, J. M. & Bishop, S. J. (). Auditory temporal
processing impairment: neither necessary nor suﬃcient for causing language impairment
in children. Journal of Speech, Language, and Hearing Research , –.

Bishop, D. V. M. & Snowling, M. J. (). Developmental dyslexia and speciﬁc language

impairment: Same or diﬀerent? Psychological Bulletin , –.

Bollen, K. A. (). A new incremental ﬁt index for general structural equation models.

Sociological Methods & Research , –.

Briscoe, J., Bishop, D. V. & Norbury, C. F. (). Phonological processing, language, and
literacy: a comparison of children with mild-to-moderate sensorineural hearing loss and
those with speciﬁc language impairment. Journal of Child Psychology and Psychiatry ,
–.

Charles-Luce, J. & Luce, P. A. (). Similarity neighbourhoods of words in young

children’s lexicons. Journal of Child Language , –.

Ching, Y. C. (). Lexical tone pattern learning in Cantonese children. Language Learning

and Communication , –.

Ciocca, V. & Lui, J. Y.-K. (). The development of the perception of Cantonese lexical

tones. Journal of Multilingual Communication Disorders , –.

Claessen, M. & Leitão, S. (). Phonological representations in children with SLI. Child

Language Teaching and Therapy , –.

Claessen, M., Leitão, S., Kane, R. & Williams, C. (). Phonological processing skills in
speciﬁc language impairment. International Journal of Speech-Language Pathology ,
–.

Corriveau, K., Pasquini, E. & Goswami, U. (). Basic auditory processing skills and
speciﬁc language impairment: a new look at an old hypothesis. Journal of Speech,
Language, and Hearing Research , –.

Dollaghan, C.

(). Spoken word recognition in children with speciﬁc language

impairment. Applied Psycholinguistics , –.

Estes, K. G., Evans, J. L. & Else-Quest, N. M. (). Diﬀerences in the nonword repetition
performance of children with and without speciﬁc language impairment: a meta-analysis.
Journal of Speech, Language, and Hearing Research , –.

Fowler, A. E. (). How early phonological development might set the stage for phoneme
awareness. In S. Brady & D. Shankweiler (eds), Phonological processes in literacy: a tribute to
Isabelle Y. Libermann (pp. –). Hillsdale, NJ: Lawrence Erlbaum Associates.

Frisina, R. D.

(). Subcortical neural coding mechanisms for auditory temporal

processing. Hearing Research , –.

Garlock, V. M., Walley, A. C. & Metsala, J. L. (). Age-of-acquisition, word frequency,
and neighborhood density eﬀects on spoken word recognition by children and adults.
Journal of Memory and Language , –.



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

Griﬃths, Y. M. & Snowling, M. J. (). Auditory word identiﬁcation and phonological

skills in dyslexic and average readers. Applied Psycholinguistics , –.

Grosjean, F. (). Spoken word recognition processes and the gating paradigm. Perception

& Psychophysics , –.

Halliday, L. F. & Bishop, D. V. M. (). Is poor frequency modulation detection linked to
literacy problems? A comparison of speciﬁc reading disability and mild to moderate
sensorineural hearing loss. Brain and Language , –.

Heath, S. M., Bishop, D. V. M., Hogben, J. H. & Roach, N. W. (). Psychophysical
functioning in dyslexia: a psychometric analysis. Cognitive

indices of perceptual
Neuropsychology , –.

Heath, S. M., Hogben, J. H. & Clark, C. D. (). Auditory temporal processing in disabled
readers with and without oral language delay. Journal of Child Psychology and Psychiatry ,
–.

Hick, R. F., Botting, N. & Conti‐Ramsden, G. (). Short‐term memory and vocabulary
development in children with Down syndrome and children with speciﬁc language
impairment. Developmental Medicine & Child Neurology , –.

Hill, P. R., Hogben, J. H. & Bishop, D. V. M. (). Auditory frequency discrimination in
children with speciﬁc language impairment: a longitudinal study. Journal of Speech,
Language, and Hearing Research , –.

Ho, C. S. H., Leung, M. T. & Cheung, H. (). Early diﬃculties of Chinese preschoolers at
familial risk for dyslexia: deﬁcits in oral language, phonological processing skills, and
print-related skills. Dyslexia , –.

Hu, L. T. & Bentler, P. M. (). Cutoﬀ criteria for ﬁt indexes in covariance structure
analysis: conventional criteria versus new alternatives. Structural Equation Modeling: A
Multidisciplinary Journal , –.

Joanisse, M. F. & Seidenberg, M. S. (). Speciﬁc language impairment: a deﬁcit in

grammar or processing? Trends in Cognitive Sciences , –.

Kidd, J. C., Shum, K. K. M., Ho, C. S. H. & Au, T. K. F. (). Phonological

representations and early literacy in Chinese. Scientiﬁc Studies of Reading , –.

Kline, R. B. (). Principles and practice of structural equation modeling. New York:

Guildford.

Leonard, L. B. (). Children with Speciﬁc Language Impairment. Cambridge, MA: MIT Press.
Linguistic Society of Hong Kong (). The LSHK Cantonese Romanization Scheme. Hong

Kong: Linguistic Society of Hong Kong.

Mainela-Arnold, E., Evans, J. L. & Coady, J. (). Lexical representation in children with
SLI: evidence from a frequency-manipulated gating task. Journal of Speech, Language, and
Hearing Research , –.

Marshall, C. R. & van der Lely, H. K. J. (). Recognition of gated verbs by children with
Grammatical-Speciﬁc Language Impairment: eﬀects of inﬂection and frequency. Journal of
Neurolinguistics , –.

Marslen-Wilson, W. D. (). Functional parallelism in spoken word-recognition. Cognition

, –.

McArthur, G. M. & Bishop, D. V. M. (). Auditory perceptual processing in people with
reading and oral language impairments: current issues and recommendations. Dyslexia ,
–.

McArthur, G. M. & Bishop, D. V. M. (a). Frequency discrimination deﬁcits in people
with speciﬁc language impairment: reliability, validity, and linguistic correlates. Journal
of Speech, Language, and Hearing Research , –.

McArthur, G. M. & Bishop, D. V. M. (b). Which people with speciﬁc language

impairment have auditory processing deﬁcits? Cognitive Neuropsychology , –.

McArthur, G. M. & Bishop, D. V. M. (). Speech and non-speech processing in people
with speciﬁc language impairment: a behavioural and electrophysiological study. Brain
and Language , –.



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

McArthur, G. M., Ellis, D., Atkinson, C. M. & Coltheart, M. (). Auditory processing
deﬁcits in children with reading and language impairments: Can they (and should they)
be treated? Cognition , –.

McMurray, B., Munson, C. & Tomblin, J. B. (). Individual diﬀerences in language
ability are related to variation in word recognition, not speech perception: evidence from
eye movements. Journal of Speech, Language, and Hearing Research , –.

McMurray, B., Samelson, V. M., Lee, S. H. & Tomblin, J. B. (). Individual diﬀerences

in online spoken word recognition: implications for SLI. Cognitive Psychology , –.

Mengler, E. D., Hogben, J. H., Mitchie, P. & Bishop, D. V. M. (). Poor frequency
discrimination is related to oral language disorder in children: a psychoacoustic study.
Dyslexia , –.

Metsala, J. L. (). An examination of word frequency and neighborhood density in the

development of spoken-word recognition. Memory & Cognition , –.

Metsala, J. L., Stavrinos, D. & Walley, A. C. (). Children’s spoken word recognition and
contributions to phonological awareness and nonword repetition: a -year follow-up.
Applied Psycholinguistics , –.

Metsala, J. L. & Walley, A. C. (). Spoken vocabulary growth and the segmental
restructuring of lexical representations: precursors to phonemic awareness and early
reading ability. In J. L. Metsala & L. C. Ehri (eds), Word recognition in beginning literacy
(pp. –). Hillsdale, NJ: Erlbaum.

Montgomery, J. (). Recognition of gated words by children with speciﬁc language
lexical mapping. Journal of Speech, Language, and

impairment: an examination of
Hearing Research , –.

Nickisch, A. & Massinger, C. (). Auditory processing in children with speciﬁc language
impairments: Are there deﬁcits in frequency discrimination, temporal auditory processing
or general auditory processing? International Journal of Phoniatrics, Speech Therapy and
Communication Pathology , –.

Raven, J. C. (). Hong Kong supplement guide to the Standard Progressive Matrices. Hong

Kong: HKSAR Government, Education Department.

Rice, M. L. (). Language growth and genetics of speciﬁc language impairment.

International Journal of Speech-Language Pathology , –.

Rice, M. L., Redmond, S. M. & Hoﬀman, L. (). Mean length of utterance in children
with speciﬁc language impairment and in younger control children shows concurrent
validity and stable and parallel growth trajectories. Journal of Speech, Language, and
Hearing Research , –.

Rinker, T., Kohls, G., Richter, C., Maas, V., Schultz, E. & Schecker, M. (). Abnormal
frequency discrimination in children with SLI as indexed by mismatch negativity (MMN).
Neuroscience Letters , –.

Roach, N. W., Edwards, V. T. & Hogben, J. H. (). The tale is in the tail: an alternative
hypothesis for psychophysical performance variability in dyslexia. Perception , –.
Rosen, S. (). Auditory processing in dyslexia and speciﬁc language impairment: Is there a

deﬁcit? What is its nature? Does it explain anything? Journal of Phonetics , –.

Sereno, J. A. & Lee, H. (). The contribution of segmental and tonal information in

Mandarin spoken word processing. Language and Speech , –.

Share, D. L., Jorm, A. F., McClean, R. & Matthews, R. (). Temporal processing and

reading disability. Reading and Writing: An Interdisciplinary Journal , –.

Snowling, M. (). Dyslexia. Oxford: Blackwell Publishers Ltd.
Stefanatos, G. A., Green, G. G. R. & Ratcliﬀ, G. G. (). Neurophysiological evidence of

auditory channel anomalies in developmental aphasia. Achieves of Neurology , –.

Stokes, S. F. (). The impact of phonological neighborhood density on typical and atypical

emerging lexicons. Journal of Child Language , –.

Sutcliﬀe, P. & Bishop, D. V. M. (). Psychophysical design inﬂuences frequency
discrimination performance in young children. Journal of Experimental Child Psychology
, –.



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

K I D D E T A L.

Sutherland, D. & Gillon, G. T. (). Assessment of phonological representations in
children with speech impairment. Language, Speech, and Hearing Services in Schools ,
–.

Tallal, P. (). Auditory temporal perception, phonics, and reading disabilities in children.

Brain and Language , –.

Tallal, P. (). Experimental studies of language learning impairments: from research to
remediation. In D. V. M. Bishop & L. B. Leonard (eds), Speech and language
impairments in children: causes, characteristics, intervention and outcome (pp. –).
Philadelphia, PA: Psychology Press.

Tallal, P. & Piercy, M. (). Developmental aphasia: rate of auditory processing and

selective impairment of consonant perception. Neuropsychologia , –.

To, C., Cheung, H., & T’sou, B. (). Hong Kong Cantonese Oral Language Assessment
Scale: a further validation study. Paper presented at the First China International
Conference for Speech Therapy, Beijing.

Tomblin, J. B., Abbas, P. J., Records, N. L. & Brenneman, L. M. (). Auditory evoked
responses to frequency-modulated tones in children with speciﬁc language impairment.
Journal of Speech and Hearing Research , –.

T’sou, B., Lee, T. H.-T., Tung, P., Man, Y., Chan, A., To, C. K. S. & Chan, Y. (). Hong
Kong Cantonese Oral Language Assessment Scale. Hong Kong: City University of Hong
Kong.

Walley, A. C., Metsala, J. L. & Garlock, V. M. (). Spoken vocabulary growth: its role in
the development of phoneme awareness and early reading ability. Reading and Writing: An
Interdisciplinary Journal , –.

Wetherill, G. B. & Levitt, H. (). Sequential estimation of points on a psychometric

function. British Journal of Mathematical and Statistical Psychology , –.

Wightman, F., Allen, P., Dolan, T., Kistler, D. & Jamieson, D. (). Temporal resolution

in children. Child Development , –.

Wong, A. M. Y., Ciocca, V. & Yung, S. (). The perception of lexical tone contrasts in
Cantonese children with and without speciﬁc language impairment (SLI). Journal of
Speech, Language, and Hearing Research , –.

Wong, A. M. Y., Kidd, J. C., Ho, C. S. H. & Au, T. K. (a). Characterizing the overlap
between SLI and dyslexia in Chinese: the role of phonology and beyond. Scientiﬁc Studies
of Reading , –.

Wong, A. M. Y., Klee, T., Stokes, S. F., Fletcher, P. & Leonard, L. B. (b).
Diﬀerentiating Cantonese-speaking preschool children with and without SLI using
MLU and lexical diversity (D). Journal of Speech, Language, and Hearing Research ,
–.

Ziegler, J. C. & Goswami, U. (). Reading acquisition, developmental dyslexia, and skilled
reading across languages: a psycholinguistic grain size theory. Psychological Bulletin ,
–.



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604

A U D I T O R Y P E R C E P T I O N A N D W O R D R E C O G N I T I O N I N S L I

Appendix

Stimuli used in the speech-gating task. (NOTE: T = Tone; O = Onset; N =
Nucleus; F = Final; Gates = number of gates required to present the whole
word; Initial gate = proportion of the target word covered in the initial
gate of  ms.)

High-frequency words

Density

Length

Word

Pronun-
ciation Meaning

T O N F Total Class

Frequency
(per ) Rank ms Gates

Initial
gate

人
面
心
錢
車
電
仔
頭

jan
min
sam
cin
ce
din
zai
tau

Man
Face
Heart
Money
Car
Electricity
Son
Head





































 High
Low

 High
 High
Low

Low

 High
 High





































·
·
·
·
·
·
·
·

Low-frequency words

Density

Length

Pronun-
ciation Meaning

Word

T O N F Total Class

Frequency
(per ) Rank ms Gates

柱
雷
岸
柄
棋
炭
蠟
賊

cyu
leoi
ngon
beng Handle
kei
taan
naap Wax
caak
Thief

Pillar
   
Lightening    
Seashore
   
   
   
   
   
   

Chess
Charcoal

 Low
 Low
 Low
 Low
 High
 High
 High
 Low










 
 
 
 
 
 
 
 










·
·
·
·
·
·
·
·



Downloaded from https://www.cambridge.org/core. Universitaetsbibliothek Kaiserslautern, on 22 Dec 2018 at 14:26:30, subject to the
Cambridge Core terms of use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0305000915000604



I N T R O D U C T I O N.  Children with Specific Language Impairment (SLI) fail to develop expressive and/or receptive oral language at the same rate and/or to the same extent as typically developing children, despite adequate intelligence, peripheral sensory functioning, exposure to language, and no neurological, emotional, or social dysfunction (Bishop, .  Leonard, .  Rice, ).  Compared to same-age peers, these children demonstrate an uneven profile of abilities across domains of language, with most experiencing difficulties in grammatical morphology and syntax, but many also demonstrating difficulties in lexical and pragmatic skills (Leonard, ).  Difficulty in lexical processes underlying spoken word recognition is well documented in SLI.  inefficiency or inaccuracy in establishing, accessing, selecting, and retrieving from stored representations of spoken language (Dollaghan, ).  For example, children with SLI tend to have smaller overall expressive/receptive vocabulary (Hick, Botting & Conti-Ramsden, ) and impaired phonological processing (Briscoe, Bishop & Norbury, ), use fewer different words per utterance (Rice, Redmond & Hoffman, .  Wong, Klee, Stokes, Fletcher & Leonard, b), and are less accurate in nonword repetition (Estes, Evans & Else-Quest, ).  Multiple accounts have been proposed to explain the different language deficits observed in children with SLI, and much research has focused on the grammatical deficit account and the processing deficit account (Joanisse & Seidenberg, .  Leonard, ).  Some researchers have also explored the possibility of deficits in specific mechanisms such as lower-level auditory perception (Corriveau, Pasquini & Goswami, .  McArthur & Bishop, a, b.  Tallal & Piercy, ), but little research to date has focused on auditory perception and word recognition deficits within the same children with SLI (but see Montgomery, ).  The present study responded to this research gap by focusing on lexical access for spoken word recognition in SLI, and whether and how it might be related to auditory perception.  Spoken word recognition and the speech-gating task.  Spoken word recognition occurs when auditory perceptual input activates a single lexical phonological representation.  Activation begins upon receipt of auditory input and is updated as the input unfolds.  The activation seems to be graded according to word- and cohort-related factors, and multiple words can be activated in parallel and actively compete until a single match is selected (McMurray, Samelson, Lee & Tomblin, ).  Word recognition can thus be conceptualized as selective elimination from an activated cohort of potential targets until the ‘isolation point’ – the point within the word for which no other word matches are possible (Marslen-Wilson, ).  Spoken word recognition may be facilitated by developmental restructuring of phonological representations.  That is, ongoing reorganization of the lexicon such that representations are stored for accuracy and expediency (e. g.  Metsala & Walley, .  Walley, Metsala & Garlock, ).  with development, primarily between ages one to eight (Fowler, ), words with overlapping phonological properties are stored more systematically for better differentiation.  Word frequency and neighborhood density (i. e.  the number of acoustically similar words) have been posited to drive lexical restructuring.  High- rather than low-frequency words should have better-developed representations because the former are activated more often.  Words from high-density phonological neighborhoods should be under relatively strong pressure to differentiate from other lexical entries to enable recognition (Charles-Luce & Luce, .  Garlock, Walley & Metsala, ).  Lexical restructuring has been observed across alphabetic languages (Ziegler & Goswami, ) – which map morphemes onto phonemes or phoneme strings – as well as a logographic language that maps morphemes consistently onto syllables (i. e.  Chinese.  Kidd, Shum, Ho & Au, ).  Speech-gating, a behavioral task that estimates the point within spoken words beyond which correct recognition is possible (Allopenna, Magnuson & Tanenhaus, .  Grosjean, ), has been used productively and widely to study spoken word recognition and lexical development models.  In a typical non-contextual forward speech-gating task, spoken words are presented from their onset in segments (or ‘gates’) typically  ms in length, with word identification attempted after hearing each gate.  On each trial, an additional gate is added, with trials only ending when each word has been heard in its entirety.  The accumulated time increment at which recognition occurs without subsequent change of mind (the ‘acceptance point’) is thought to reflect the temporal window over which word recognition occurs.  This temporal window has been suggested to directly reflect the underlying organization of the representation.  well-established structure facilitates expedient word recognition because the cohort of incorrect matches can be rapidly discounted, and less-established representations impede word recognition because the cohort remains protractedly active (Metsala, ).  Thus the speech-gating task has been used to quantify the underlying structure of the phonological representations supporting spoken word recognition.  Consistent with this, Metsala observed that time taken to correctly identify gated words decreased with age, and that word frequency and neighborhood density effects were predicted by lexical restructuring.  These findings have been replicated in other gating studies (Griffiths & Snowling, .  Kidd et al. , .  Metsala, Stavrinos & Walley, ).  Speech-gating in SLI.  Speech-gating has been used for assessing spoken word recognition in SLI.  Dollaghan () compared SLI children with typically developing age-matched controls on their recognition of gated familiar and unfamiliar words.  There were no group differences for familiar words, but children with SLI needed to hear more of the unfamiliar words to recognize them than did the controls.  These findings did not support a task-related impairment.  Instead, the deficit seemed specific to the phonological representations of unfamiliar words and the ability to distinguish them from the better-established representations of familiar words.  Accessing less-established representations probably increases processing demands, leaving word recognition vulnerable.  Children with SLI were also less likely to produce the correct initial consonant at the earliest gate for all word types, suggesting lower-level auditory perceptual deficits that impede the initial acoustic-phonetic analysis (Dollaghan, ).  Montgomery () used speech-gating of highly familiar words to examine whether children with SLI were impaired in ‘lexical mapping’ (i. e.  lexical access and lexical activation) – the stage when auditory perceptual input undergoes acoustic-phonetic analysis.  No group differences were found between children with SLI and their typically developing peers matched on either age or vocabulary, arguing against word recognition and low-level auditory perceptual deficits in SLI (Sutherland & Gillon, ).  Mainela-Arnold, Evans, and Coady () likewise observed neither group difference in spoken word recognition isolation points between SLI children and age-matched controls, nor any interaction between SLI status, word frequency, and neighborhood density.  However, children with SLI vacillated more between the target and incorrect cohort items after the isolation point, suggesting that word recognition in SLI is more vulnerable to interference from competing activated representations.  This finding was replicated by Marshall and van der Lely ().  Wong, Kidd, Ho, and Au (a) found that Cantonese-Chinese speaking children with SLI (particularly those with comorbid dyslexia) had significantly later isolation points for high-frequency words, and for high-density words, compared to language-typical peers as well as children who had a history (but no current diagnosis) of SLI.  These findings suggest that the phonological representations of children with SLI have not been restructured to the same extent as those of typically developing children.  Importantly, the subpar speech-gating performance observed in SLI could not be attributed to overall poorer vocabulary because the deficit was limited to high-frequency words and high-neighborhood-density words.  Collectively, the findings on speech-gating and SLI hint at difficulties in some aspects of spoken word recognition in SLI, particularly in Cantonese Chinese.  Wong et al. ’s (a) study stands alone in the literature by reporting frequency and density effects in SLI using speech-gating.  However, given their focus on SLI–dyslexia comorbidity, of the twenty children with a current diagnosis of SLI, only ten had SLI without comorbid dyslexia.  Therefore, the robustness of the findings from speech-gating regarding SLI remains unclear.  The present study therefore set out to take a closer look at these effects, particularly those reported in Wong et al. ’s (a) study, in a much larger sample of children with SLI.  Phonological processing in SLI.  Difficulties in phonological processing skills are well documented in SLI (e. g.  Bishop & Snowling, ).  Snowling () hypothesized that phonological deficits might lead to poorer quality phonological representations, which might in turn impair the development of phonological processing skills.  Poorly established representations would be difficult to access and use, limiting phonological awareness (e. g.  syllable awareness, onset and rime awareness, phoneme deletion, etc. ).  Poorer quality phonological representations might also impair access and retrieval of phonological information, evident via slower and perhaps more errant Rapid Automatized Naming (RAN) performance.  Likewise, the ability to maintain phonological information in short-term memory sufficient to either create or refine phonological representations will likely influence the quality of the representations (Claessen, Leitão, Kane & Williams, ).  There are potentially very informative relations between phonological processing skills and the structure of the underlying representation, particularly in SLI.  However, these relations have not been fully explored using the speech-gating task to quantify the underlying structure of the phonological representation.  To do so was a goal of the present study.  Auditory perception in SLI.  According to McMurray et al.  (), subpar speech-gating suggests more lexical decay – entropy in lexical representations – in SLI that prevents full activation of some, if not all, phonological representations, rendering them vulnerable to active competitors.  This can explain why children with SLI take longer than language-typical controls to reach the acceptance point after the isolation point.  However, it does not explain the difficulties with the initial consonant in SLI reported by Dollaghan ().  an additional account is in order.  One possibility is that children with SLI have low-level auditory perceptual deficits (Dollaghan, .  McArthur & Bishop, .  Rosen, ).  Tallal () reported that ‘language learning impaired’ children were less able to differentiate and/or sequence brief tones (i. e.  different tones at short inter-stimulus intervals, ISI).  Such a deficit in ‘temporal processing’ was hypothesized to inhibit accurate perception of rapid transitions in speech and to impair “the formation of distinct (categorical) phonological representations, leading to delay or disruption in language” (Benasich & Tallal, , p.  ), also implicating phonological processing skills, and potentially reading skills, in this causal chain (e. g.  Tallal, ).  Auditory perception in SLI has been studied using variations of Tallal’s auditory repetition task and other putative ‘temporal’ auditory tasks (e. g.  backward detection/recognition masking, gap detection, tracking of rapid spatial changes.  Rosen, ), with equivocal results.  Importantly, the potential mediating role of phonological representations in the hypothesized relation between auditory perception and phonological processing skills has not been explicitly examined.  No study has yet examined whether both the quality of phonological representations pertinent to spoken word recognition – assessed with speech-gating – and low-level auditory perception are impaired in the same individuals with SLI.  Without such empirical information, these causal relations must remain speculative.  Tallal’s () auditory repetition task inherently conflates frequency discrimination (FD) with general stimulus-based judgments.  Note that people with SLI often struggle with practice trials for the auditory repetition task where tone discrimination, not temporal processing, was stressed (Heath, Hogben & Clark, ), so poorer performance was not limited to short ISIs during the task proper (e. g.  Share, Jorm, McClean & Matthews, ).  Neither is poor performance necessarily limited to ‘temporal’ tasks – indeed Nickisch and Massinger () found reduced performance in SLI only on tasks with an FD component, not those assessing temporal processing.  These results collectively suggest a difficulty with FD in SLI, at times (though not always) exacerbated by task-related pressures.  Poor FD may well turn out to undermine language learning, particularly in tonal languages such as Cantonese Chinese (Wong, Ciocca & Yung, ).  Speech comprises rapid changes in spectral information.  Deficits in fine-grained FD can mean difficulties discriminating spectral patterns in speech signals, which can in turn degrade phonological representations (McArthur & Bishop, a).  There is behavioral, as well as electrophysiological evidence, that at least some children with SLI perform poorly on FD tasks (Hill, Hogben & Bishop, .  McArthur & Bishop, a, b.  .  McArthur, Ellis, Atkinson & Coltheart, .  Mengler, Hogben, Mitchie & Bishop, .  Rinker, Kohls, Richter, Maas, Schultz & Schecker, ), and continue to do so over time (Hill et al. , ).  Nonetheless, because poor FD does not consistently predict SLI, more research is needed to clarify this (Halliday & Bishop, .  Rosen, ).  Accurate speech processing also seems to require sensitivity to modulations in frequency (Frisina, ).  According to Bailey and Snowling (), reduced sensitivity to frequency modulation (FM) when young children are establishing and refining phonological representations may well affect subsequent language ability.  In a typical FM detection task, the modulation rate is fixed and the depth is varied across trials, and the task is to differentiate modulated from un-modulated tones.  Stefanatos, Green, and Ratcliff () found markedly reduced auditory-evokedresponses to FM tones among children with SLI, but Tomblin, Abbas, Records, and Brenneman () could not replicate this.  Bishop, Carlyon, Deeks, and Bishop () speculated that the severity of receptive impairments might be at issue, and their own research revealed a non-significant trend for elevated FM thresholds in SLI, but the thresholds did not predict phonemic awareness.  The exact contribution of FM to speech recognition, then, remains unclear.  <Middle> The present study.  The mixed findings on FD and FM in SLI call for empirical clarification.  Crucially, little research has focused on how spoken word recognition deficits fit with potential auditory perception deficits in SLI.  The present multilevel investigation therefore examined FD, FM, and speech-gating within the same children – children with a diagnosis of SLI, and age-matched controls.  With a relatively large sample, we focused on two main questions.  .  Do children with SLI perform worse than age-matched language-typical controls on spoken word recognition (assessed via speech-gating), frequency discrimination (FD), and frequency modulation (FM).  .  Does performance on the speech-gating task mediate any relation between auditory thresholds, phonological processing, and oral language. Participants.  The sample comprised  native speakers of Cantonese Chinese aged between .  and . , mean .  (years. months), attending kindergarten in Hong Kong.  Fifty-seven ( male,  female) met criteria for SLI (Bishop, .  Leonard, ).  they performed below age-expected levels in receptive and/or expressive language, passed cognitive and hearing screening, and demonstrated no history or signs of neurological or psychosocial problems.  Fifty of them had already been diagnosed with SLI when recruited from government-run Child Assessment Centers via voluntary referral from speech pathologists.  The remaining seven, recruited from local kindergartens, were classified as SLI at the time of testing.  Five senior students in speech–language pathology, under the supervision of an experienced speech–language pathologist, confirmed the SLI status of these fifty-seven children using the Hong Kong Cantonese Oral Language Assessment Scale (HKCOLAS.  T’sou et al. , ) – a standardized test with local norms for diagnosing language impairments in children aged five to twelve.  These children all failed (i. e.  scoring · SD below the mean) two or more of the six subtests in the HKCOLAS, and met the other conventional diagnostic criteria (Leonard, ).  Their nonverbal IQ scores all fell within the normal range on the Raven’s Standard Progressive Matrix according to local age norms (Raven, , Table ).  The fifty-three children ( male,  female) in the language-typical control group were recruited from kindergartens in Hong Kong.  They passed a language screening, scoring no worse than · SD below the age-normed mean on the Cantonese Grammar and the Nominal Expressive Vocabulary subtests of the HKCOLAS – the two subtests recommended for assessing preschool and first-year primary school children when under administration time constraints (To, Cheung & T’sou, ).  In the Cantonese Grammar test, children were asked to match pictures with the sentences heard, answer questions targeting specific grammatical morphemes, and make grammaticality judgments about complex sentences.  For the Expressive Vocabulary subtest, children were shown pictures of objects and asked to name them.  Children in the control group were also given the Narrative Retell subtest, whereby they listened to a story and retold it to a naive listener.  Scoring was based on story content and the use of referring expression, connectives, and complex sentences in the retell.  Non-verbal IQ scores in the control group all fell within the normal range of locally normed Raven’s Standard Progressive Matrix scores (Raven, ).  All children passed a hearing screening of pure tones of ·, , , and  KHz presented at  dB in both ears, measured using a Grason-Stadler GSI model  calibrated audiometer.  No children were reported to have otitis media around the time of testing, or to have a diagnosis of attention deficit and/or hyperactivity disorder, or other psychosocial problems.  All children spoke Cantonese Chinese as their first and dominant language.  Descriptive and comparative statistics for both groups are presented in Table .  Materials.  Psychometric tasks.  .  Phonological processing.  . .  Phonological awareness.  In a syllable-deletion task adopted from Ho, Leung, and Cheung (), children were asked to repeat real Chinese words composed of three syllables each, while deleting one of its syllables from the beginning, middle, or end of the word.  An example, translated to English, would be.  ‘Please say little-fat-pig.  Now say little-fat-pig again, this time without saying fat. ’ Deletion of a syllable results in either a real word or a nonword.  The maximum score for this task was .  . .  Phonological short-term memory.  In a non-word repetition task (Ho et al. , ), children were asked to repeat nonwords with two to six syllables.  These non-words were meaningless combinations of actual Cantonese morphemes, with one syllable per morpheme.  A child received  point for each of the syllables correctly repeated and  point for correct ordering of any two consecutive syllables.  Points were deducted for adding syllables.  The maximum score for this task is .  . .  Rapid Automatized Naming (pictures.  RAN-p).  Children were asked to name five common objects (sun, apple, butterfly, airplane, fan) depicted by line drawings, presented randomly in a  ×  matrix, as quickly and as accurately as possible (Ho et al. , ).  Each child named them from left to right, one row after the other.  Children were asked to complete the task twice, the score being the time taken to name the twenty drawings, averaged across two trials.  Experimental tasks.  .  Frequency Discrimination (FD).  This task was modeled on that used by Hogben and colleagues (Heath, Bishop, Hogben & Roach, .  Hill et al. , .  Mengler et al. , ), and was administered with a Matlab program via headphones on a laptop computer.  In each trial, stimuli were three  ms binaural pure tones with  ms rise/fall and  ms ISI, presented in the AXB format.  The first tone (A) was a  Hz standard, and the third comparison tone (B) had a frequency of  Hz plus the frequency difference for that trial.  The middle tone (X) was the same frequency as either (A) or (B), which varied randomly across trials.  Each child was to indicate, by pressing either ‘’ or ‘’ on the keypad, which of tones A or B matched tone X.  Feedback was given via the presentation of a cartoon ‘sad’ or ‘smiley’ face on the screen.  The frequency difference between the standard and comparison tones was varied between trials via an adaptive -up, -down staircase reversal procedure (Wetherill & Levitt, ), which estimated the % correct performance level.  The initial frequency difference was  Hz. 
I N T R O D U C T I O N.  In everyday conversations adults perceive speech by ear and eye, yet the development of this critical audiovisual property of speech perception is still not well understood.  In fact, the extant child research reveals that – compared to adults – children exhibit reduced sensitivity to the articulatory gestures of talkers (i. e.  visual speech).  The McGurk task (McGurk & MacDonald, ) well illustrates this maturational diﬀerence in sensitivity to visual speech.  In this task, individuals are presented with audiovisual stimuli with conﬂicting auditory and visual onsets (e. g.  hear /ba/ and see /ga/).  Whereas adults typically perceive a blend of the auditory and visual inputs (e. g.  /da/ or /ða/) and rarely report perceiving the auditory /ba/, children, by contrast, report perceiving the /ba/ (auditory capture) % to % of the time (McGurk & MacDonald, ).  Because visual speech plays a role in learning the phonological structure of spoken language (e. g.  Locke, .  Mills, ), it is critical to understand how children utilize visual speech cues.  The influence of visual speech on children’s audiovisual speech perception clearly increases with age, but the precise timecourse for achieving adultlike benefit from visual speech remains unclear.  Numerous studies report that (i) children from roughly five through eleven years of age benefit less than adults from visual speech whereas (ii) adolescents (preteens–teenagers) show an adultlike visual speech advantage (e. g.  Desjardins, Rogers & Werker, .  Dodd, .  Erdener & Burnham, .  Jerger, Damian, Spence, Tye-Murray & Abdi, .  McGurk & MacDonald, .  Ross, Molholm, Blanco, Gomez-Ramirez, Saint-Amour & Foxe, .  Tremblay, Champoux, Voss, Bacon, Lepore & Theoret, .  Wightman, Kistler & Brungart, ).  Developmental improvements in sensitivity to visual speech have been attributed to changes in (i) the perceptual weights given to visual speech (Green, ), (ii) articulatory proficiency and/or speechreading skills (e. g.  Desjardins et al. , .  Erdener & Burnham, ), and (iii) linguistic skills and language-specific tuning (Erdener & Burnham, .  Sekiyama & Burnham, ).  Notable complications to this story are suggested, however, by several studies reporting significant sensitivity to visual speech in three- to five-year-olds (Holt, Kirk & Hay-McCutcheon, .  Lalonde & Holt, ), six- to seven-year-olds (Fort, Spinelli, Savariaux & Kandel, ), and eight-year-olds (Sekiyama & Burnham, , ).  Some of these studies stressed that performance in young children can be influenced by visual speech when the children are tested with developmentally appropriate measures and task demands.  This viewpoint encourages us to consider the possible bases underlying children’s developmental insensitivity to visual speech.  Toward this end, Jerger et al.  () adopted a dynamic systems theoretical viewpoint (Smith & Thelen, ).  Dynamic systems theory.  Dynamic systems theory proposes two relevant points for understanding the influence of visual speech in children.  (i) multiple interactive factors form the basis of developmental change, and (ii) children’s early skills are ‘softly assembled’ systems that reorganize into more mature, stable forms in response to environmental and internal forces (Smith & Thelen, ).  Evoked potential studies support such a developmental reorganization and restructuring of the phonological system (Bonte & Blomert, ).  During these developmental transitions, processing systems are less robust and children cannot easily use their cognitive resources.  thus performance is less stable and more affected by methodological approaches and task demands (Evans, ).  From this perspective, children’s reduced sensitivity to visual speech may be incidental to developmental transformations, their processing by-products, and experimental contexts.  Clearly, previous research has shown a greater influence of visual speech on children’s performance when task demands were modified to be more child-appropriate (Desjardins et al. , .  Lalonde & Holt, ).  Further, sensitivity to visual speech has been shown to vary in the same children as a function of stimulus/task demands (Jerger, Damian,Tye-Murray & Abdi, ).  We propose that some experimental variables that might have contributed to children’s reduced sensitivity to visual speech are the use of (i) complex tasks/ audiovisual stimuli (e. g.  targets embedded in noise or competing speech.  McGurk stimuli with conflicting auditory and visual onsets) – because they make listening more challenging or less natural and familiar – and (ii) high-fidelity auditory speech – because it makes visual speech less relevant.  The purpose of the present research was to evaluate whether sensitivity to visual speech in children might be increased by the use of stimuli with (i) congruent onsets that invoke more prototypical and representative audiovisual speech processes, and (ii) non-intact auditory onsets that increase the need for visual speech without involving noise.  Below we briefly introduce our new stimuli and discuss the current task and its possible benefits for studying the influence of visual speech on performance by children.  Stimuli for the New Visual Speech Fill-In Effect The new stimuli are words and nonwords with an intact consonant/rhyme in the visual track coupled to a non-intact onset/rhyme in the auditory track (our methodological criterion excised about  ms for words and  ms for nonwords.  see ‘Method’).  Stimuli are presented in audiovisual vs.  auditory modes.  Example stimuli for the word bag are.  (i) audiovisual.  intact visual (b/ag) coupled to non-intact auditory (–b/ag) and (ii) auditory.  static face coupled to the same non-intact auditory (–b/ag).  Our idea was to insert visual speech into the ‘nothingness’ created by the excised auditory onset to study the possibility of a Visual Speech Fill-In Effect (Jerger et al. , ), which occurs when performance for the SAME auditory stimulus DIFFERS depending upon the presence/absence of visual speech.  Responses illustrating a Visual Speech Fill-In Effect for a repetition task (Jerger et al. , ) are perceiving /bag/ in the audiovisual mode but /ag/ in the auditory mode. 
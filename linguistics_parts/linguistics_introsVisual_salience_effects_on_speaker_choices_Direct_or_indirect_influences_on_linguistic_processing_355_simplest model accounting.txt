 When speakers talk, they are normally trying to give linguistic form to a notion they have in their heads that they wish to implant in their interlocutors’ heads.  Insofar as speakers can and do describe things that they are seeing either at that very moment or with their minds’ eyes, it is logical to think that visual characteristics will have an inﬂuence on speaker choices regarding most obviously the content, but also the ﬁnal form of their descriptive utterances.  Vision has been found to inﬂuence language in many ways.  For example, a character who is looked at ﬁrst for perceptual reasons is more likely to be mentioned ﬁrst (e. g. , Gleitman, January, Nappa, & Trueswell, 2007.  Myachykov, Garrod, & Scheepers, 2012.  Myachykov, Thompson, Garrod, & Scheepers, 2011).  looks to characters in an image have been consistently found to predict mention of the ﬁxated characters (e. g. , Coco & Keller, 2012.  Coco, Malcolm, & Keller, 2014.  Grifﬁn, 2001) and their properties (Haskell, 2005.  Meyer, van der Meulen, & Brooks, 2004.  van der Meulen, 2001).  and visual content inﬂuences choice of referring expression (Fukumura, van Gompel, & Pickering, 2010).  However, speakers are not always describing a scene, and even when they are, some of the information conveyed is not straightfordwardly attributable to something the speakers perceive or have a perceptual memory of.  Moreover, the information derived from the visual system is unlikely to be in a format that can be directly transferred to the linguistic system.  Some kind of translation is required (Jackendoff, 1987).  In short, the blueprints for sentences are likely to come from a conceptual representation of the perceived event, rather than from the perceived event itself (Bunger, Papafragou, & Trueswell, 2013.  Vogels, Krahmer, & Maes, 2013).  Although most researchers will probably agree with the previous statement, some explanations of perceptual inﬂuences on language production seem to either disregard the existence of an intermediate level of event conceptualization or confound it with sentence preparation under the implicit assumption that what you see is what you say (Ibbotson, Lieven, & Tomasello, 2013.  Montag & MacDonald, 2013.  Myachykov et al. , 2012.  Myachykov, Thompson, et al. , 2011), rather than determining what you may want to say.  More speciﬁcally, looks to elements in a scene are linked directly with the building blocks of sentence production rather than with the way the scene is apprehended (see, e. g. , Myachykov, Posner, & Tomlin, 2007, p.  464, their ﬁgure 2.  Myachykov, Thompson, Garrod, et al. , 2011).  In consequence, the fact that speakers’ gazes are drawn to a speciﬁc object and this object is then chosen as the syntactic subject of the ﬁnal description is taken to mean that the starting point in sentence production is a lexical item rather than a syntactic frame (Gleitman et al. , 2007.  for a detailed description of the “syntactic planning starting point” debate, see Bock, Irwin, & Davidson, 2004).  In truth, however, even when perceptual salience correlates with choice of starting point in a sentence, it is possible that the perceptual properties are inﬂuencing how the event is conceptualized rather than linguistic planning directly (Vogels et al. , 2013).  Cueing a participant in a scene may be one way of anchoring the way the event is interpreted, which could make the cued character then become the topic of the linguistic message, what Bock and Ferreira (2014) call the “aboutee,” and thus be the ﬁrst mentioned noun by virtue of its conferred conceptual status.  This would be similar to the special status conferred by other conceptual properties such as animacy, which also inﬂuences linguistic choices (Ant´on-M´endez, Gerfen, & Ramos, 2016.  Branigan, Pickering, & Tanaka, 2008.  Brawley, 2012.  Hickmann, Taranne, & Bonnet, 2009.  Prat-Sala & Branigan, 2000).  To determine which of the two mechanisms, scene conceptualization or lexical activation, is responsible for the observed effects of visual salience on linguistic output, it would be necessary to pitch the visual manipulation against another manipulation thought to affect at least one of these two levels of processing.  for example, a linguistic prime.  Myachykov et al.  (2012) conducted such an investigation.  In their Experiments 1 and 2, the researchers looked at the proportion of active descriptions of depicted transitive events (e. g. , a cowboy punching a boxer) after a linguistic prime consisting of either a matching or a nonmatching verb (e. g. , punch vs.  kiss), and a visual prime in the form of a dot directing attention to the location of one of the two characters prior to the image appearing on screen.  They found that visually cueing the agent of the event (e. g. , the cowboy) increased the proportion of active descriptions but only when the linguistic prime was the nonmatching irrelevant verb (e. g. , kiss).  For the authors, this interaction points to the effect of perceptual manipulations on syntactic choice over and above the effect of a verbal prime.  There is an alternative interpretation of these results, however, since there was an imbalance between the two kinds of priming in Myachykov et al. ’s design.  the visual manipulation primed one or the other participants in an unambiguous event, but the linguistic one either primed or did not prime the event.  The interaction could thus be due to the visual cue having an effect only in the absence of a “useful” linguistic one, while when there is a matching linguistic prime, the visual cue did not make any difference.  To create a more balanced design, the scenes to be described should allow linguistic priming in both directions, something that can best be achieved by the use of perspective predicates (Gleitman et al. , 2007).  To investigate whether perceptual manipulations inﬂuence sentence production directly through lexical access, the following experiments were designed to look for the effects that visual salience would have on sentence production if it inﬂuenced linguistic processing directly by determining order or mention or argument assignment.  Speciﬁcally, the experiments looked for the effects of visual priming on scenes that can be described from two complementary perspectives (e. g. , a chasing event is also a ﬂeeing event), in the presence of a linguistic prime.  The linguistic priming consisted of a verb associated with one of the two perspectives of the event to be described (e. g. , either “chase” or “ﬂee”), which should inﬂuence descriptions by biasing the speaker toward the associated conceptualization of the event (i. e. , reading the word “chase” should make the reader think in terms of chasing and interpret the coming scene from that perspective).  and the visual priming consisted of a preview of one of the two characters involved in the event (e. g. , the robber or the cop in a chase scene being shown ahead of the full scene), which draws the eyes to ﬁrst land on the intended character when the complete scene appears.  <Middle> PREDICTIONS.  A scene depicting a cop chasing a robber who is ﬂeeing (see Figure 1) can be described in one of two main ways.  as a regular active sentence from a chasing perspective (e. g. , “the cop is chasing the robber”) or from a ﬂeeing perspective (e. g. , “the robber is ﬂeeing from the cop”).  In addition, speakers may also choose to describe the scene using either a passive sentence (e. g. , “the robber is being chased by the cop”), or a sentence where the direct object has been placed in a more prominent position (e. g. , “the robber, the cop is chasing him”).  Which of these forms gets chosen should depend on whether the speaker is already primed to think about or construe the scene as a chasing or ﬂeeing event after encountering one of the two verbs.  Assuming incremental sentence production (see review of lexicalist frameworks in Bock et al. , 2004.  Kempen & Hoenkamp, 1987.  Levelt, 1989), characters who are more visually salient and therefore are made more accessible should tend to dictate how to describe the scene in which they appear by being processed earlier and, thus, determining the sentence’s starting point, as has been found (e. g. , Gleitman et al. , 2007.  Prat-Sala & Branigan, 2000).  In Experiment 1, the scenes to be described are preceded by either a linguistic or a visual prime, but not both, to test the predicted inﬂuences of each type of prime on description choice.  In particular, a linguistic prime that is known to always match the scene to be described should create an expectation of what the coming scene will be about and, thus, shape the linguistic intention of how to describe it (Myachykov et al. , 2012).  Therefore, a linguistic prime on its own should inﬂuence how the scene is construed (as a chasing or a ﬂeeing event) and how often it is described from the associated perspective.  that is, there should be more chase descriptions when “chase” is the prime than when “ﬂee” is the prime.  In the case of visual primes, they are also expected to inﬂuence the choice of descriptions by either (a) making the associated lexical item more accessible to start with (Gleitman et al. , 2007.  Myachykov et al. , 2007, p.  469) and thus more likely to be mentioned early.  or (b) promoting the salient entity to a syntactically prominent position such as subject (Tanaka, Branigan, McLean, & Pickering, 2011.  Tomlin, 1997).  In the case of active sentences, both possibilities would result in the same kind of description.  one in which the visually primed character is expected to be the subject.  Therefore, under conditions that do not promote alternative sentence structures, more chase descriptions would be expected after visually priming the cop than after visually priming the robber.  Furthermore, when each prime type is acting independently, we do not expect a difference in the time needed to start speaking depending on the priming direction (i. e. , whether the linguistic prime is “chase” vs.  “ﬂee,” or whether the cop or the robber is visually primed) as there is no reason to believe that one of the priming directions carries any advantage over the other in terms of lexical access or facilitating sentence preparation.  In Experiment 2, the two types of primes are combined to answer the main research question.  whether perceptual salience has a direct effect on linguistic processing by determining a sentence’s starting point.  If the visual prime affects lexical accessibility while the linguistic prime acts by promoting one of the two construals of the scene, the two inﬂuences could be accommodated in the eventual verbal description.  a referent made more accessible could be processed ﬁrst and should, at any rate, affect the time needed for sentence preparation (Smith & Wheeldon, 1999.  Wheeldon, Ohlson, Ashby, & Gator, 2013).  This means that, at the very least, visually priming the cop should result in shorter sentence preparation times when the speaker is preparing a congruent chase description due to the linguistic prime favoring a chasing construal, but in longer preparation times when the speaker is preparing an incongruent ﬂee description because the linguistic prime favors a ﬂeeing construal. 1 Therefore, a statistical interaction would be expected for sentence preparation times because the direction of priming of the visual cue would be associated with opposite effects depending on the direction of the linguistic prime.  An effect of visual salience on lexical accessibility could also affect the form of the description instead of (or in addition to) how long it takes to start talking.  For example, if the linguistic prime induces a construal of chasing while the lexical item for “robber” is more accessible, the speaker could take advantage of the increased accessibility of this lexical item by fronting the object (e. g. , “the robber, the cop is chasing him”), or uttering a passive sentence (i. e. , “the robber is being chased by a cop”).  In this case, visually priming the robber should result in more alternative syntactic structures than visually priming the cop when the linguistic prime favors a chasing description, and in fewer such structures when the linguistic prime favors a ﬂeeing description.  Therefore, as for sentence preparation times, a statistical interaction would be expected with respect to the number of alternative syntactic structures.  Such an effect would mean that visual salience affects order of mention (ﬁrst ready, ﬁrst out) and possibly even syntactic assignment (ﬁrst one ready must be the subject).  In turn, this would be evidence of sentence production proceeding in a very piecemeal fashion, something that has been termed radical incrementality (Ferreira & Swets, 2002).  Object fronting, however, is very unusual in English, so while this language would allow us to see if visual salience affects syntactic function assignment by examining passive production, it would not be as useful in looking at the potential effects on order of mention independently of syntactic function.  Spanish, in contrast, has more ﬂexibility in word order and, therefore, more options for speakers to alter the order of mention leaving all else unchanged (e. g. , “al ladr´on lo persigue un polic´ıa,” “the robber, the cop chases”).  Spanish offers, thus, an additional opportunity to see the independent effects of visual and linguistic priming on event description, speciﬁcally on order of mention, should these exist.  Finally, in addition to considering description choices and voice onset times (VOTs), eye movements during the interval of sentence preparation were also analyzed.  These data were intended, ﬁrst, to conﬁrm that the visual manipulation was effective and, second, to explore the effect of the linguistic prime on looking patterns.  Furthermore, to the extent that visual features of the scene can impact speaker choices, we would expect to see some parallelism between looking patterns and description choices.  That is, we would expect the impact of the manipulations on looking patterns to be reﬂected on description choices.  Throughout the article, the term construal is used to refer to how a scene is conceptualized and described.  This is strongly related but different from the term perspective, which is used to refer to the actual verbs used as primes.  Thus, a linguistic cue priming a certain perspective (e. g. , “chase” primes a chasing perspective) could result in a verbal description that indicates a compatible construal of the scene (i. e. , as a chasing event.  e. g. , “the robber is being pursued”).  EXPERIMENT 1.  The total number of conditions (nine) that would have resulted from crossing three levels (no priming plus priming one of the two alternatives) of two different dimensions (visual and linguistic priming), together with the limited number of picturable perspective predicates, necessitated the breakdown of the study into two experiments.  Experiment 1 included the simple, uncrossed, linguistic and visual conditions to determine the effect of each type of manipulation, linguistic and visual, on their own.  Based on previous studies, the prediction was that both linguistic and visual manipulations would have an effect on looks to the characters and choice of verbal description.  However, there is no empirical or logical reason to believe that priming one character instead of another, or priming one verb instead of another, will have an effect on sentence preparation times.  In addition, Experiment 1 also included a nonverbal baseline condition for eye-movement data to rule out visual biases unrelated to the manipulations. Participants.  Participants in this experiment were 44 English-speaking students (M age = 21. 3, SD = 4. 60.  42. 5% male) from the University of California, San Diego, and 45 Spanish-speaking students (M age = 23. 8, SD = 5. 54.  22. 5% male) from either the University of Oviedo or the Autonomous University of Madrid (Spain).  American participants were paid US $5, and Spanish participants were paid €5 for their participation.  All the participants included were native speakers of either English or Spanish, and all considered themselves monolingual.  In the two experiments reported here, acceptable eye-tracking data loss per participant was set at 20% of all samples.  In Experiment 1, this threshold resulted in four English-speaking and three Spanish-speaking participants being excluded from the analyses.  Two more Spanish participants were excluded.  one because of eye-tracker failure, and one due to voice recording failure.  Materials.  Experimental stimuli consisted of 30 colored drawings made by the author depicting perspective predicates (see Figure 1 for an example), that is, events involving two characters doing complementary actions (e. g. , selling and buying, chasing and ﬂeeing). 2 The experimental drawings came in two versions that were mirror images of each other.  The experimental drawings were selected from a set of 33 given to 24 native monolingual English speakers (34% males, 100% aged between 18 and 29) and 24 native monolingual Spanish speakers (44% males, 74% aged between 18 and 29, 26% aged between 30 and 59) to describe in their own native language.  In this norming study, the drawings were presented one at a time using the survey program Qualtrics (Qualtrics LLC, 2005).  Participants were asked to type a sentence describing each scene in a blank window underneath the drawing.  From this set of 33, 30 drawings, which were found to be successful in eliciting the intended sorts of responses, were chosen.  For the selected pictures, intended perspective descriptions were given on average 73% of the time (SD = 17%) in English and 67% (SD = 16%) in Spanish.  In most cases, speakers showed a clear preference for one of the two scene construals of the event.  On average, one of the alternatives was chosen 87% of the time (SD = 13%) by English speakers, and 90% of the time (SD = 12%) by Spanish speakers.  This alternative was labeled the “dominant construal” of the event, as opposed to the secondary, or “subordinate construal” of the event (e. g. , a description of the scene as a chasing-event indicated a dominant construal of the event, and a description of the scene as a ﬂeeing-event indicated a subordinate construal of the event).  Only one of the items had an even distribution of preferences in English and relatively even in Spanish (the construal preferentially shown in Spanish was considered the dominant construal in this case).  Paired t tests conﬁrmed the differences between dominant and subordinate construals in both languages (in English, t = 11. 26, p = . 000.  in Spanish, t = 12. 65, p = . 000), and the similarities of dominant-to-subordinate ratios across languages (t = –1. 79, p = . 084).  This norming study also provided the speciﬁc verbs that each drawing would be paired with as linguistic primes.  one for each of the two complementary construals (e. g. , “chase” or “ﬂee”.  “perseguir” or “huir”).  These were selected to be one-word verbs that had been used by norming study participants in their descriptions (or close synonyms if the actual verbs used were not appropriate for the design).  There were also 30 ﬁller drawings,3 15 depicting a transitive action and 15 an intransitive one.  These drawings contained only one character (e. g. , a man chopping wood or a child sleeping).  Mirroring the experimental conditions, twoﬁfths of them were paired with a verb that described the depicted event, two-ﬁfths were preceded by a preview of the character, and one-ﬁfth had no primes.  Finally, there were also 4 practice drawings.  See Appendix A for a list of linguistic and visual primes.  Design and procedure.  The stimuli were presented using E-Prime software, version 2. 0.  The ﬁrst part of the experiment presented 6 experimental and 6 ﬁller drawings, all of them unprimed, for the participant to watch at leisure, without having to describe the scene.  Participants were unaware that the experiment would later require verbal descriptions.  They were told they ﬁrst had to examine the drawings carefully one by one while their eye movements were monitored, and later they would see them all together and would have to tell the experimenter which one(s) they had liked best and worst.  This served as the nonverbal eyemovement baseline intended to ﬁnd out whether the scenes themselves induced any perceptual biases.  In the second part of the experiment, there were four conditions according to whether the drawings were preceded by a linguistic prime consisting of one of the two perspective verbs (a verb denoting the preferred perspective pointing toward the dominant construal, or a verb denoting the dispreferred perspective pointing toward the subordinate construal), or a visual prime consisting of a preview of one of the characters in the drawing to be described (the agent in the dominant construal was labeled the preferred agent, and the agent in the subordinate construal was labeled the dispreferred agent).  This operationalization of perceptual salience is arguably more naturalistic than the more inconspicuous attention capture method used in other studies (e. g. , Gleitman et al. , 2007.  Kuchinsky, 2009.  Myachykov, Garrod, & Scheepers, 2011), although the two types of attention capture do not seem to differ in their linguistic effects (Myachykov, Thompson, Garrod, et al. , 2011).  In any case, because the aim is to see how something that catches our visual attention affects further linguistic processing, it is irrelevant whether the visual attention is captured by means of a location marker or a preview of the character, as long as the attention is captured.  Stimuli were counterbalanced across 10 lists.  2 drawing orientations (mirrorinverted versions of the same drawing) × 5 conditions (nonverbal baseline, or paired with either one of the linguistic primes or one of the visual primes).  Each condition was represented by six experimental items in each list.  All participants saw all drawings only once in an individually randomized order (except that the stimuli in the nonverbal baseline were always presented at the beginning, as explained).  The procedure depicted in Figure 14 was as follows.  A cross-hair appeared in the middle of the screen and remained there until the participant had ﬁxated it for a minimum of 100 ms.  Afterward, a row of hashes was presented in the middle of the screen for 100 ms.  For items with a linguistic prime, this followed the hashes for 100 ms, long enough for the participant to be fully aware of it.  For items with no linguistic prime, the screen was left blank for 100 ms.  This was followed by an interval of 300 ms.  Next, for items with a visual prime, the prime was presented for 100 ms (or a blank screen if there was no visual prime).  An audible click signaled the coming into view of the to be described scene, which participants were asked to describe in terms of who was doing what to whom without thinking too much about it.  The resulting interval between linguistic prime and scene onset provided enough time for the participant to process the priming word at a semantic level before encountering the stimulus (cf.  N400.  Kutas & Hillyard, 1980), thus ensuring the prime could elicit the intended linguistic expectation of what the scene would be about.  Nevertheless, participants were told that, although some of the scenes would be preceded by a word, which would always be related to it, they did not need to use it in their descriptions.  It was stressed that they should say whatever came to mind ﬁrst.  The presentation of the visual prime right before the stimulus matches previous studies (see, e. g. , Gleitman et al. , 2007.  Kuchinsky & Bock, 2010.  Myachykov et al. , 2012).  This ensures that the elicited saccadic movement, which takes between 100 and 200 ms (Fischer & Ramsperger, 1984), will result in a ﬁxation on the cued position within the stimulus itself.  The experiment was self-paced.  Data coding.  The experiment produced three types of data.  verbal descriptions, VOTs, and eye movements.  Verbal descriptions were recorded with a 96-kHz digital recorder.  The ELAN program was used for transcribing.  The English descriptions were transcribed by a research assistant and coded partly by a research assistant and partly by the author.  The Spanish descriptions were entirely transcribed and coded by the author.  The coding was later rechecked in its entirety by the author to ensure consistency and correct mistakes.  In those sentences coded by the research assistant and rechecked by the author (74% of the English data), there were 11% coding discrepancies, which were resolved by the author in accordance with the following coding guidelines.  Sentences were coded with regard to the construal of the event reﬂected by the verb used in the description and to their syntactic structure.  Regarding construal, the description was coded as “dominant construal” if the verb used was the preferred perspective verb or a synonym (e. g. , chase, pursue, follow, or run after).  as “subordinate construal” if the verb named the dispreferred perspective (e. g. , ﬂee, run away from, or escape).  or as “something else” if it did not name either perspective.  Regarding syntactic structure, the sentence could be a regular “active” (e. g. , “a thief is trying to escape the long arm of the law”).  could be a regular “passive” (e. g. , “the white-collar criminal is being chased by a policeman”).  contain an object placed in a more prominent position by dislocation or altered word order (“prominent object”.  e. g. , “a robber it is that the cop is chasing”).  or be coded as “something else” if it did not describe the scene as a perspective predicate (e. g. , “a crime has been committed”), did not contain a verb (e. g. , “a chase”), or the participant misinterpreted the scene.  It should be noted that the alternative syntactic structures (i. e. , passives and prominent objects) were only consistently possible in both languages for the dominant event construals (see Appendix A).  Because some arguments are indirect, rather than direct objects for many of the dispreferred perspective verbs, descriptions of the subordinate event construal did not all allow passivization or, in Spanish, object dislocation.  Therefore, analyses of syntactic choice were restricted to dominant construal descriptions (other analyses did include all responses).  VOTs were manually measured in ELAN either by a research assistant or by the author.  VOTs measured the interval between when the scene to be described appeared on the screen (marked by the click on the sound spectrograph) and the ﬁrst word uttered.  Descriptions started after some kind of nonverbal physiological sound (e. g. , snifﬂe, cough, laugh) were excluded from VOT analyses, and so were all cases where there were disﬂuencies on the initial noun phrase, or where the initial word was not part of the ﬁnal description (i. e. , self-corrections).  Together with missing data points (e. g. , undetectable clicks or voice onsets due to noise in the spectrograph), this resulted in the exclusion of approximately 22% of the utterances in the English data set (evenly distributed across conditions) and about 15% of the utterances in the Spanish data set (also quite evenly distributed across conditions).  Participants’ eye movements were tracked with a portable Tobii X-30 taking samples at 30 Hz.  The drawings were divided into two areas of interest, each containing one of the characters in the event.  the preferred agent or the dispreferred agent.  The absence of background ensured that gazes would fall on one or the other character, as there was little else to look at.  The target for the eye movement data and analyses was the preferred agent, that is, the character who would be the agent in the dominant construal.  In the analyses of VOT and verbal descriptions, untransformed reAnalyses.  sponse data were modeled with linear mixed-effects logistic regression (Jaeger, 2008) using lme4 in R version 3. 1. 3 (Bates, Maechler, Bolker, & Walker, 2014.  R Core Team, 2015) and lmerTest to calculate the resulting coefﬁcients’ degrees of freedom (Satterthwaite approximation) and associated p values (Kuznetsova, Brockhoff, & Christensen, 2014).  For the analyses on verbal descriptions, the dependent variable was binomial (dominant construal descriptions out of all descriptions, i. e. , dominant and subordinate construal descriptions), so a GLMER with a binomial link was used.  Full models initially included (unless otherwise speciﬁed) the three ﬁxed factors of linguistic priming (preferred or dispreferred perspective, or prime absent), visual priming (preferred or dispreferred agent, or prime absent), and language (English or Spanish).  These ﬁxed factors were contrast coded and centered as follows.  linguistic priming with preferred perspective = 0. 5, with dispreferred perspective = –0. 5, absent = 0.  visual priming with preferred agent = 0. 5, with dispreferred agent = –0. 5, absent = 0.  Spanish = 0. 5.  and English = –0. 5.  A maximal random effect structure including random intercepts and slopes over subjects and items was always attempted ﬁrst (Barr, Levy, Scheepers, & Tily, 2013).  However, nonconvergence issues usually forced a gradual simpliﬁcation of the random effects, which was implemented by ﬁrst eliminating the higher order factors and then the random slopes of language and priming as required (Barr et al. , 2013).  The models were subjected to systematic reduction of the ﬁxed effects and subsequent chi-square comparison of models’ ﬁts.  This allows us to ﬁnd the simplest model with the highest explanatory value as ﬁxed factors that do not affect the results can be excluded from the model without signiﬁcantly affecting the model’s ﬁt.  For the eye movement data, growth curve analyses (Mirman, Dixon, & Magnuson, 2008) were carried out on the empirical logit (elogit) transformed dependent variable of looks to target (the preferred agent) for data collapsed by either subjects or items and aggregated in 100-ms time bins starting from the time the whole scene came into view.  For these analyses, only trials associated with valid descriptions in the active voice were included.  that is, passives and unintended descriptions were excluded.  As there were no a priori predictions regarding the speciﬁc time course of eye movements, the intervals of interest were determined from visual inspection of the participants’ scan patterns and based on clear curve inﬂection points.  Two intervals of interest emerged.  from onset of the complete scene to be described (stimulus onset) to 400 ms, and from 400 to 1200 ms.  The overall time course of ﬁxations was modeled with a ﬁrst- (linear) and a second- (quadratic) orthogonal polynomial and always a maximal random effect structure consisting of random effects of time terms over subjects and items, respectively, as well as over subject-by-linguistic priming and subject-by-visual priming (in the subjects’ analyses), or item-bylinguistic priming, item-by-visual priming, and item-by-language priming (in the items’ analyses).  In these analyses, a signiﬁcant intercept for a given main effect or interaction indicates an overall difference of total looks to the target due to the main effect or interaction.  an effect of the linear term gives an indication of whether ﬁxations rose or fell.  and an effect of the quadratic term indicates a difference across the time window in the dynamics of eye movements directed at the target.  As with the analyses of verbal descriptions, a procedure of systematic ﬁxed effect reduction was followed to arrive at the simplest model with the best ﬁt.  In order to make the Results section easier to follow, only the simplest models with the best ﬁt are reported.  Results and discussion.  Verbal descriptions.  Figure 2 shows the number of verbal descriptions reﬂecting the dominant or subordinate construal for each priming condition, with the dominant construal responses broken down into actives (e. g. , “the cop is running after the thief” or the “the thief is running from the cop”) and passives (e. g. , “a robber is being chased by a cop”).  No prominent object sentences were produced in English and only two in Spanish.  one in the dispreferred linguistic priming condition and one in the dispreferred visual priming condition.  All the subordinate construal descriptions were regular actives as expected (see Data coding section).  The simplest model accounting for choice of dominant construal (e. g. 
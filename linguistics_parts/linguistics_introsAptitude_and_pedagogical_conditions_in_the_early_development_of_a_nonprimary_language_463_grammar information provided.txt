The ﬁeld of second language acquisition has always tried to understand the construct of aptitude, which has often been used to refer to cognitive abilities implicated in language learning (e. g. , Robinson, 2005a).  This interest stems from the need to understand the underlying cognitive processes involved in language learning.  Traditionally, aptitude was seen as the abilities that were measured by the Modern Language Aptitude Test (MLAT) developed by Carroll and Sapon in 1959.  The test contained ﬁve sections.  number learning, phonetic script, spelling cues, words in sentences, and paired associates, which were suggested to measure the following.  rote learning ability and memory, phonetic coding ability, inductive language learning, and grammatical sensibility.  Despite its shortcomings and the presence of new tests such as the Cognitive Ability for Novelty in Acquisition of Language—Foreign and the LLAMA Language Aptitude Test (see Skehan, 2012), the MLAT is still being widely used as it is considered one of the most successful predictors of language learning, both in instructional contexts (Ehrman & Oxford, 1995.  Erlam, 2005.  Harley & Hart, 1997.  Winke, 2013) and in laboratory studies (DeGraaff, 1997.  Robinson, 1997).  Nevertheless, and in order to account for the multicomponential view of the construct, current research prefers to report results on speciﬁc subtests of the MLAT rather than a composite score.  Two subtests that have been found to be good predictors of language learning are the paired associates subtest (e. g. , Hummel, 2009.  Robinson, 1997), which measures rote memory (RM), and the words in sentences subtest (e. g. , Erlam, 2005.  Li, 2013), which measures grammatical sensitivity or linguistic analytic ability (LAA).  One of the subcomponents of aptitude that has received more attention is memory.  Early interpretations of memory (Atkinson & Shiffrin, 1968) considered short-term memory (STM) a storage mechanism through which information was transferred to long-term memory by means of rehearsal.  Baddeley and Hitch (1974) later argued that STM should be replaced with working memory (WM), a system concerned not only with storage but also with active processing.  Skehan (2002) and Robinson (2005a) suggested expanding the traditional view of aptitude by integrating WM measures into “a much broader battery of aptitude subtests than operationalized in MLAT and other traditional tests” (Robinson 2005a, p.  51).  One of the most acknowledged models of WM is the multiple-component model developed by Baddeley and Hitch (1974) and later modiﬁed by Baddeley (2000), which views WM as a system consisting of (a) a central executive, to control and regulate attention.  (b) a phonological loop, involved in retaining verbal information in a temporary store.  (c) a visuospatial sketch pad, which maintains visual or spatial information.  and (d) an episodic buffer, a temporary storage system that integrates the information processed in the other subsystems and long-term memory.  Baddeley suggests that the combination of the processing and storage components of WM can help predict individual differences in cognitive skills such as reading, comprehension, and reasoning.  In addition, this model considers the central executive an attentional system (Baddeley & Logie, 1999), and therefore it closely relates attention, and consequently language learning, to WM.  Research looking at the role of WM in second language (L2) acquisition has adopted different perspectives.  While one line of research looks at the role of the phonological loop on L2 acquisition with the implementation of phonological STM (PSTM) tests, another approach explores the role of both storage and processing capacity and implements sentence span tests (Daneman & Carpenter, 1980) as WM measures.  Both lines of investigation have found that there is a relationship between WM and L2 learning (see Williams, 2012, for a review).  An important issue that has obvious implications for L2 learning and teaching is whether the role of aptitude varies depending on the type of instruction received.  This issue has been investigated in different aptitude–treatment interaction (ATI) studies (see Vatz, Tare, Jackson, & Doughty, 2013).  The present study attempts to contribute to this line of research by investigating whether cognitive abilities such as LAA, RM, WM, and PSTM play a different role in language development depending on the learning conditions (i. e. , presence or absence of grammar explanation while providing corrective feedback).  With the inclusion of four different measures, this study hopes to account for the current multicomponential view of aptitude and to provide a broader picture of the cognitive skills that play a role in language learning.  The following section provides an overview of relevant studies that have investigated ATI and include at least one of the aptitude measures proposed in the present study.  Although Krashen (1981, 1982) claimed that aptitude inﬂuences language learning only in conditions that promote explicit learning (see Robinson, 2002, 2005a, for a discussion on this issue), other researchers such as Skehan (1998, 2002) argue that aptitude plays a larger role in more informal (e. g. , non-classroom immersion) contexts, as learners are under more pressure when processing input.  Laboratory settings, however, show that the picture is not clear and that results vary with the learning condition and the cognitive measure implemented (DeGraaff, 1997.  Robinson, 1997, 2002.  Sanz, Lin, Lado, Bowden, & Stafford, 2014.  Tagarelli, Borges Mota, & Sanz, 2014.  Tagarelli, Ruiz, Moreno, & Rebuschat, 2016) De Graaff (1997) investigated the learning of a language adapted from Esperanto (eXperanto) in a laboratory setting.  Fifty-four participants were asked to learn simple and complex morphological and syntactic forms in 150 hr of computer-based lessons, during which they had to read dialogue translations, complete vocabulary activities, and practice interpreting and producing the target forms.  There were two groups that varied in degrees of explicitness.  an explicit group, with explicit rules presented before practice and during the provision of feedback on the correctness of their answers in the activities.  and an implicit group, with the same corrective feedback (right/wrong) but without rule presentation before or during the activities.  Acquisition was measured by grammaticality judgment and production tests.  An adaptation of the MLAT in Dutch containing the “words in sentences” and “paired associates” tests was administered.  The results from the aptitude tests were collapsed so that correlations analyses could be run.  It was revealed that the explicit group performed better on all language tests and on simple and complex forms.  In addition, it was found that aptitude correlated with performance on language tests.  However, there was no interaction between aptitude and treatment condition.  aptitude was positively related to language performance not only in the explicit but also in the implicit condition.  Robinson (1997) also measured aptitude with the MLAT in a laboratory study that included different degrees of explicitness.  One hundred four English L2 students were distributed into four different treatments to learn an “easy rule” (subject–verb inversion is allowed in sentences where adverbials of movement/location are fronted) and a “hard rule” (how to form pseudoclefts of location).  The four conditions varied depending on whether participants were instructed to memorize the stimuli (implicit), to comprehend it (incidental), to look for rules (rule search), or were exposed to the rules in advance (instructed).  The training sessions exposed participants to 2 sets of 40 sentences (20 based on the easy rule and 20 on the hard rule).  Acquisition was measured by a grammaticality judgment posttest, and aptitude was measured using the “words in sentences” and “paired associated” subtests of the English MLAT.  The results revealed that the scores on the words in sentences test signiﬁcantly correlated with learning in the implicit, rule-search, and instructed conditions, but not in the incidental condition.  The strongest correlations were obtained for the implicit condition.  No correlations were found for this condition between RM and language learning.  Therefore, it was LAA (and not memory) that seemed to be playing a role in language learning in the implicit condition.  Moreover, results revealed correlations between the most explicit condition and RM, not only for the easy rule but also for the hard rule.  In addition, the scores of the participants in the rule-search condition, which could be considered the second most explicit, correlated with RM for the hard rule.  These ﬁndings seem to indicate that aptitude inﬂuences language learning in both explicit and implicit conditions.  However, when the conditions are explicit and include learning or looking for rules, it appears that (although with different strengths of relationships) more aptitude constructs are involved than when conditions are more implicit.  The lack of relationship between these aptitude measures and language learning in the incidental condition was later partially supported by Robinson (2002, 2005b).  This study showed that in conditions involving processing for meaning rather than focus on form, traditional measures of aptitude were not good predictors of immediate language learning.  Robinson compared the performance of 38 participants in three different tasks.  explicit, implicit, and incidental.  The implicit and incidental tasks were comparable to those in Robinson (1997).  In the explicit task, participants were told to complete a series of letter strings that were presented on a computer screen.  Following the last trial, participants completed a grammaticality judgment posttest (written and aural), an awareness questionnaire, and a production posttest.  One-week and 6-month delayed tests were also completed.  Aptitude was measured by the Language Aptitude Battery for Japanese, which was based on traditional aptitude measures such as the MLAT, and a WM reading span test.  In line with Krashen (1981, 1982), the analyses showed that aptitude was related to performance in the more explicit learning condition, but not in the implicit condition, or in the incidental posttest measures (although it was found to be related to the 6-month incidental production delayed posttest).  The results in the implicit condition seem to contradict Robinson (1997), although the aptitude measures were not wholly comparable.  Whereas in Robinson (1997) the aptitude subtest that correlated with implicit conditions was the grammatical sensitivity component of the MLAT, in Robinson (2002), the Language Aptitude Battery for Japanese included memory, grammatical sensitivity, and ability to match sounds and symbols.  The results on the incidental measures did, however, support those in Robinson (1997), as aptitude measures did not correlate with immediate learning in either of the two studies.  On the contrary, WM was found to be related only to incidental learning in immediate and 1-week delayed listening grammaticality judgment (GJ) posttests and in 1-week and 6-month delayed guided production posttests.  The researcher concluded that traditional aptitude measures tend to correlate more with explicit learning conditions.  WM, on the contrary, may be more relevant for incidental learning, a condition that emphasizes processing for meaning.  Tagarelli et al.  (2014) also investigated the role of WM in three different conditions.  incidental (sentence repetition and plausibility judgment, n = 29), intentional (rule discovery, n = 26), and control (n = 15).  The two experimental groups listened to 120 grammatical sentences with three speciﬁc verb-order rules.  Learning was measured by a GJ posttest that included items not previously seen (60 semantically plausible and 60 implausible).  WM capacity was measured by an operation–word span task and a letter–number ordering task.  The results indicated that the intentional group outperformed the incidental group and that both groups outperformed the control.  A positive correlation between performance and WM was found only for the intentional group on grammatical items.  A parallel study by Tagarelli et al.  (2016) investigated the interaction between WM and PSTM (among other cognitive variables), learning conditions, and linguistic complexity in 50 participants exposed to the same artiﬁcial language as in Tagarelli et al.  (2014).  Incidental (n = 25) and instructed (with provision of rule, n = 25) conditions were designed to promote learning.  No signiﬁcant correlations were found between WM or PSTM and learning in the more explicit condition when considering all items in the test, suggesting that providing metalinguistic instruction levels the ﬁeld for learners.  However, when the items were separated, the results revealed a positive correlation between PSTM and performance on grammatical and complex items in the instructed groups, which led researchers to conclude that learners with good PSTM beneﬁted from explicit instruction.  Neither of the two studies reported by Tagarelli et al.  included a delayed test, an important limitation to bear in mind when comparing these results with other similar studies.  A recent laboratory study by Sanz et al.  (2014), which was conducted within the Latin Project paradigm like the present study, investigated the relationship between WM capacity and language learning in two conditions that varied in the presence or absence of a grammar lesson before an interactive treatment (with input-based practice and explicit feedback).  Sanz et al.  included L2 Spanish intermediate learners who were exposed to Latin (a third language) for the ﬁrst time.  The results revealed that WM predicted learning on interpreting written and aural input only when participants were not exposed to the prepractice grammar lesson, which led researchers to conclude that WM capacity may play more of a role when metalinguistic information is limited to reactive feedback.  While these studies investigated the role of aptitude in a laboratory study, other research has examined different aptitude measures in relation to classroom learning.  In Erlam (2005), 92 high school students were assigned to one of four groups.  control, deductive instruction, inductive instruction, and structured instruction.  In the deductive instruction condition, participants received explicit instruction with rule presentation, followed by form-focused activities that required participants to produce the target form, both in writing and in speech.  Corrective feedback was also provided.  In the inductive instruction group, students did not receive any rule explanation or explicit metalinguistic information about the target form, but participated in a series of both input- and output-based activities.  Finally, in the structured input instruction treatment, which was input based, participants received explicit information and rule explanation about direct object pronoun forms.  Unlike the other two groups, participants in this group did not have to produce the target form.  Each group received three sessions of 45 min of instruction on direct pronouns in French.  Pre/post and delayed tests included listening and reading comprehension tests, as well as written and oral production tests.  Three tests were administered.  the words in sentences component of the MLAT, the sound discrimination test of the Pimsleur Language Aptitude Battery, and a PSTM test.  Analyses between gain scores and aptitude scores for each treatment revealed correlations between the words in sentences and the listening comprehension immediate gain for the inductive group, and between the same aptitude measure and the written production for both the inductive (delayed gain) and the structured input group (immediate and delayed gain).  Finally, PSTM also correlated with the immediate and delayed gain scores of the structured input group.  Contrary to some of the ﬁndings in laboratory studies, none of the aptitude measures correlated with the most explicit treatment (deductive).  It needs to be noted, though, that learners under this treatment were exposed to rule presentation, metalinguistic feedback, and input and output practice, a combination that was not present in laboratory treatments.  In addition, whereas in laboratory studies participants were college students, Erlam’s study was conducted with high school learners.  The researcher concluded that this type of treatment neutralized individual differences in language aptitude.  Limitations of this study include the lack of processing component in the WM measure and the lack of control in the amount and nature of the feedback provided.  Especially relevant for the present study is research investigating the role of aptitude in the effect of feedback on language development.  Along these lines, a number of studies have explored the role of recast or metalinguistic feedback under an interaction approach (Goo, 2012.  Li, 2013.  Sagarra & Abbuhl, 2013a, 2013b).  Goo (2012) investigated whether WM mediated acquisition of the English that-trace ﬁlter under three different conditions (oral recast, oral metalinguistic feedback, and control).  Participants were 54 Korean EFL learners completing two one-way information gap activities as well as pre- and post-grammaticality judgment test (GJT) and written production tests.  Consistent with the claim that WM may be more relevant in more implicit conditions, the results revealed that WM mediated learning only in the oral recast group.  Caution is needed when interpreting these results due to the lack of delayed test and the small sample size (n = 14).  Li (2013) investigated whether the effect of recasts or metalinguistic feedback on the acquisition of an opaque linguistic structure (Chinese perfective –le) was mediated by two aptitude constructs.  LAA and WM as measured by the words in sentences subtest of the MLAT and a listening span test, respectively.  The results indicated that WM was negatively correlated with performance on the delayed GJT in the metalinguistic feedback group.  LAA, however, was positively correlated with the same test scores.  The results also revealed a near-signiﬁcant positive correlation between WM and scores on the immediate GJT in the recast group (r = . 34, p = . 07).  These results seem to conﬁrm that LAA plays an important role under conditions where learners receive feedback with metalinguistic explanations.  The role of aptitude mediating grammar learning under explicit conditions is further supported by Li’s (2015) meta-analysis and Skehan’s (2015) critical overview.  Another study on interactive feedback by Sagarra and Abbuhl (2013a) investigated the role of WM on the development of gender and number agreement in L2 Spanish in six experimental treatments that provided different types of feedback.  written or oral utterance rejection, written or oral unenhanced recasts, and written (with bold and capitalized font) or oral (with stress) enhanced recasts.  Participants were required to complete a computerized ﬁll-in-the-blank activity with the correct form of the adjective.  WM was found to be related to written and oral accuracy as well as to production in a face-to-face interactional posttest for the enhanced and unenhanced oral recasts.  Sagarra and Abbuhl (2013b) completed a follow-up study where feedback was provided in four groups as follows.  written enhanced recasts, written unenhanced recasts, written unenhanced recasts with a pretask grammar explanation, and no feedback.  Unlike in their ﬁrst study, WM did not play a signiﬁcant role in L2 learning.  The researchers explained that this could have happened because all feedback in this second study was written, which was suggested to be easier to process than aural feedback and therefore less sensitive to WM effects.  More research is needed to fully understand to what degree WM plays a role in pedagogical approaches that include feedback.  In sum, 20 years of ATI research conducted so far provide an intricate picture of the role that different cognitive abilities play in language learning under different learning conditions.  Research suggests that learning under both explicit and implicit conditions is constrained by a number of cognitive abilities as measured by both traditional (LAA and RM) and more recent measures of aptitude (WM and PSTM.  De Graaff, 1997.  Li, 2013.  Robinson, 1997, 2002.  Sanz et al. , 2014.  Tagarelli et al. , 2014, 2016).  Speciﬁcally, it seems that under more explicit conditions (when rules are provided before and during a language lesson), the role of aptitude may be neutralized (Erlam, 2005.  Sanz et al. , 2014), although evidence of its role in such conditions also exists (DeGraaf, 1997).  In addition, the relationship between aptitude and language learning under explicit conditions seems to be more consistent with traditional measures of aptitude than with WM (Li, 2013.  Robinson, 2002), which appears often in less explicit treatments, that is, when rules are provided reactively during feedback, but not before the practice as a result of interacting with the input (Sanz et al. , 2014) or under rule-discovery conditions (Tagarelli et al. , 2014).  WM also appears to be related to language learning frequently in more implicit environments, that is, when providing recasts during interaction (Li, 2013.  Sagarra & Abbuhl, 2013a), or during incidental learning conditions (Robinson, 2002).  The disparity of results may be due, among other reasons, to the different approaches taken.  laboratory (e. g. , De Graaff, 2007.  Sanz et al. , 2014) versus classroom-type research (Erlam, 2005).  learning conditions not comparable among studies (e. g. , computerized delivered feedback lesson as in De Graaff, 1997.  or Sanz et al. , 2014.  vs.  face-to-face as in Li, 2013.  or Goo, 2012).  aptitude measures implemented (e. g. , WM listening span test, as in Sanz et al. , 2014.  or WM reading span test, as in Robinson, 2002, 2005b.  MLAT, as in DeGraaff, 2007.  or Pimsleur Language Aptitude Battery, as in Erlam, 2005).  Scoring procedures also seem to play a role in the results obtained (e. g. , using an aptitude composite score, as in DeGraaff, 2007, or separate subtest scores, as in Robinson, 1997).  This last option, however, seems to be preferred in more recent research.  Finally, time of testing (posttest vs.  delayed) accounts for some of the different results (e. g. , unlike in Tagarelli et al. , 2014, where no delayed tests were implemented, WM seemed to play a signiﬁcant role in retention under incidental learning conditions in Robinson, 2002).  More research is needed in order to fully understand the nature of the role of aptitude in different pedagogical approaches to language learning.  Especially relevant for L2 researchers and practitioners is research that incorporates different types of feedback as it resembles pedagogical approaches adopted not only in traditional classrooms but also in hybrid and online courses.  In computer-assisted language learning, computers provide feedback that is usually “immediate, provided only when needed, individualized, and focused on the key form” (Sanz, 2004, p.  12).  Thus, understanding how aptitude relates to language learning under different computerized environments is necessary to help teachers and practitioners accommodate learners better while maximizing their time in front of the computer.  Following recent accounts that include different aptitude measures to tap into a wider variety of cognitive abilities, the present study included WM measures (WM and PSTM) to complement traditional aptitude measures (LAA and RM) in an attempt to answer the following research question.  what is the relationship between the cognitive factors under investigation (WM, PSTM, LAA, and RM) and the development of Latin’s morphosyntax under two learning conditions that differ in the presence or absence of metalinguistic explanations in the feedback provided during input-based practice.  In order to answer this research question, we compare the relationship between aptitude and language learning under two different computerized learning conditions.  In the ﬁrst condition, the lesson provides input-based practice with right/wrong correction with metalinguistic feedback (+MF).  In the second condition, the lesson is identical but the feedback provided does not contain metalinguistic feedback (–MF).  Instead, it only provides right/wrong correction.  It is important to note that, although more implicit, this second condition is still explicit and cannot be fully comparable to implicit conditions such as those provided by recasts (e. g. , Li, 2013).  Previous studies have included one comparable condition to ours (+MF in DeGraaff, 1997, and Sanz et al. , 2014, and –MF in Sagarra & Abbuhl, 2013a).  In addition, these comparable studies have only used one aptitude measure (composite score of the MLAT in DeGraaff, 1997, and WM in Sagarra & Abbuhl, 2013a, and Sanz et al. , 2014).  However, no studies have looked at the role of different aptitude abilities in the effects of computer-delivered reactive feedback (with or without metalinguistic information) provided during practice.  <Middle> METHODS.  The present study is part of the Latin Project (Lado, Bowden, Stafford, & Sanz, 2014.  Lenet, Sanz, Lado, Howard, & Howard, 2010.  Sanz, Lin, Lado, Bowden, & Stafford, 2009.  Sanz et al. , 2014.  Stafford, Bowden, & Sanz, 2012), which adopts an interactive perspective to the study of individual differences and learning contexts.  The following section follows similar methodology as that of previous studies conducted under this paradigm.  Participants.  Participants were 58 college-level native speakers of English whose ages ranged from 18 to 22 years old and who were randomly assigned to the +MF (n = 33) or –MF (n = 25) groups.  In an attempt to control for previous language experience, participants were all in a second-year Spanish program and had no knowledge of Latin or any other case-marking language.  Participants with one or two semesters in a noncase language were accepted.  Therefore, in some cases, Latin was the fourth language rather than the third language.  In addition, participants scoring 67% (8 out of 12) or higher on the pretests were not included in the ﬁnal sample described above.  Although this percentage may seem high, half of the test sentences were presented in subject–verb–object (SVO) word order, which may have aided educated guessing on the pretest, thereby inﬂating scores.  All participants were compensated for their participation with extra credit.  Target structure.  The linguistic target of the study was the assignment of thematic agent/patient roles to nouns in Latin via case morphology.  The theoretical framework that guided the design of our materials was the competition model (CM), developed by Bates and MacWhinney (1989).  In CM terms, it is argued that when processing language, the assignment of functional meanings to grammatical forms in the input involves competition, which is governed by the “cue validity” of the linguistic input.  Cue validity refers to the availability (frequency of appearance) and reliability (degree to which a cue leads to the correct interpretation) of a particular cue in the input.  In the present study, the targeted linguistic forms were noun and verb morphology that indicate thematic agent and patient roles in Latin (i. e. , “who does what to whom”).  In Latin, the strongest cue (i. e. , the most available and reliable) is case morphology, followed by subject–verb agreement, and ﬁnally, word order.  This sequence is reversed in the participants’ ﬁrst language (L1), English, in which word order is the strongest cue.  In contrast, in Spanish, the participants’ L2, verb agreement is the strongest cue, followed by word order (Bates & MacWhinney, 1989).  System learning in CM terms is understood as the application of a new cue hierarchy to novel input.  in the current study, system learning is investigated through the inclusion of novel (i. e. , untrained) test items.  Following principles that have been shown to lead to reliable linguistic gains in processing instruction research (VanPatten, 2005), the input was manipulated in ways that would encourage a change in the processing strategy, from one based on word order to another that prefers noun and verb morphology for sentence interpretation.  Practice sentences were manipulated so that neither word order nor subject–verb agreement was a consistently reliable cue.  Given the cue hierarchy of English, the prediction was that when participants ﬁrst read a sentence, such as “Parvul-um specta-t angel-us” (boy-masc.  sing.  obj.  looks at-sing.  angel-masc.  sing.  Subj.  “The angel looks at the boy”), and were asked to choose between two possible English translations (The boy looks at the angel or The angel looks at the boy), they would by default respond assuming SVO word order (their L1 cue), which would lead to an incorrect answer.  Provision of immediate negative feedback might then lead them to restructure their system and shift their reliance to a more reliable cue, in this case, noun case morphology. 1 Given these manipulations and the fact that practice could not be performed successfully by relying solely on the lexical meaning of the nouns and verbs, on word order, or on verbal morphology, participants were led to process both noun and verb morphology as a means of successful task completion.  Experimental design.  The experiment consisted of three sessions over 4 weeks.  all took place in an Apple laboratory, where participants interacted with an application that combined ColdFusion and Flash programming to deliver audiovisual treatments and capture participants’ responses.  During the ﬁrst session, participants completed a consent form and a background questionnaire followed by a computer-delivered vocabulary lesson and quiz.  Next, they completed three pretests (written interpretation, aural interpretation, and written GJ).  During the second session, approximately 1 week later, participants completed the computer-delivered treatment and three immediate posttests.  At the ﬁnal session, 2 weeks later, participants completed three delayed posttests and an online debrieﬁng questionnaire.  Vocabulary lesson.  Presentation of vocabulary was timed (12 min) as a means to control exposure.  Each Latin noun (n = 35) was presented onscreen as follows.  two pictures representing the noun in singular and plural appeared ﬁrst, and then the singular and plural, masculine and feminine subject (nominative) and object (accusative) case forms (8 forms total) were presented aurally and in written form, followed by a written English translation.  There was no explanation of what the noun morphology indicated, though written singular forms were presented under singular pictures and plural forms under plural pictures.  Each Latin verb (n = 11) was presented beginning with two pictures representing the action, followed by the inﬁnitive verb form (written and aural) and the written English translation.  Immediately following the vocabulary lesson, participants were quizzed on the word meanings via a multiple-choice quiz.  In order to ensure that vocabulary knowledge was sufﬁcient for comprehension of word meanings in the practice session, participants with a score of 60% or higher on this quiz reviewed the vocabulary items they had missed until they reached 100% accuracy.  Participants with a score below 60% repeated the entire vocabulary lesson and then the quiz until they reached 100%.  Right after the vocabulary lesson and quiz, participants completed the pretests.  Treatment practice and feedback.  Participants interacted with a computerdelivered practice session involving interpretation of written and aural Latin sentences.  Practice consisted of six different tasks with 9 or 10 items per task.  All practice items included two answer choices, with reversed roles for subject and object.  thus, participants had to make a choice that hinged on interpretation of the critical form (noun case morphology indicating subject/object) when interpreting sentences.  Participants responded via key press and received immediate feedback that remained onscreen for 5 s before the program advanced automatically to the next practice item.  Following guidelines for developing structured input activities (Lee & VanPatten, 2003), both aural and written comprehension-based tasks were included.  Task 1 presented a written Latin sentence and two English translation choices.  Task 2 presented a written sentence and two picture choices.  Task 3 presented a picture and two written Latin sentence choices.  Task 4 presented an aural sentence and two English translation choices.  Task 5 presented an aural sentence and two picture choices.  Task 6 presented a picture and an aural sentence, and participants had to decide whether or not the picture shown matched the sentence heard.  Although the order in which the tasks were presented was ﬁxed, item order was randomized within each task.  All participants received feedback on both correct and incorrect responses during the practice session.  In the +MF group, feedback conﬁrmed or rejected the response and included metalinguistic information about the target form.  Metalinguistic information included the existence of an error, the source of the error, and the appropriate grammatical rule.  An example is provided in Figure 1.  Feedback provided after a correct response is similar to that presented in Figure 1 but included a positive word such as right.  The –MF group was identical except for the fact that feedback did not include metalinguistic information on the target form, but only informed participants of the correctness or incorrectness of the answer provided (right/wrong feedback).  Language tests.  Three language tests were administered.  a written interpretation (WI) test, an aural interpretation (AI) test, and a written GJT.  Three versions of each test, with equivalent but different items, were created, and these were administered as pretest, posttest, and delayed test.  The order of test version presentation was counterbalanced across participants and test sessions.  The WI and AI tests followed the same design as Tasks 2 and 5 in the practice session.  participants were instructed to select the corresponding picture (from two choices), or the additional “I don’t know” response.  Each test consisted of 20 items (i. e. , sentences).  12 critical (6 trained, 6 untrained) and 8 distractors.  Whereas the pictures in critical items represented reversed subject/object roles, as in the practice tasks, the pictures in distractors depicted entirely different scenes (different subjects, actions, and objects), so that items could be answered using only vocabulary knowledge, without attention to form and meaning of the target structures.  On the GJT, participants read a sentence and indicated whether it was grammatical or not (or “I don’t know”) via key press.  Like the interpretation tests, this test included 20 items, 12 critical (4 trained, 8 untrained) and 8 distractors.  Of the 12 critical items, 6 were grammatical and 6 were ungrammatical.  Of the 6 ungrammatical items, 2 had incorrect case endings, 2 had incorrect subject–verb agreement, and 2 contained both of these errors.  The distractor sentences contained one noun and a verb rather than two nouns and a verb.  The scoring procedure was straightforward.  one point was awarded for each correct answer to the 12 critical items, making 12 the maximum score on each of these three tests.  According to Cronbach α values (min = 0. 671 to max = 0. 870), test reliability was medium to high across all tests.  Aptitude tests design, scoring, and analyses.  In order to determine participants’ WM capacity, a sentence span test(adapted from Daneman & Carpenter, 1980) similar to the one used in other studies conducted under the Latin Project (e. g. , Sanz et al. , 2014) was administered in the participants’ L1 to account for both the processing and the storage functions of WM.  Participants listened to sets of 3, 4, or 5 sentences (4 sets of each length for a total of 48 sentences), each of whose ﬁnal word was a concrete noun.  They were asked to make two judgments for each sentence.  determine whether the sentence made sense or not and whether the sentence was grammatical or not.  A sentence was considered ungrammatical when it included grammar violations of subject–verb agreement, verb tense, or article.  Nonsense sentences were those that included a semantic anomaly (e. g. , animacy violation).  At the end of each set of sentences, participants were asked to recall aloud the ﬁnal word of each sentence in the set.  None of the words to be recalled were semantically related.  Recall was not timed.  once participants had recalled the words, they moved on to the next set of sentences with a mouse double click.  The average total time spent on this test was approximately 15 min.  The scoring of the WM listening span test took into account both the processing and the storage components of the test.  One point was assigned for each correct judgment (one for grammatical and one for sense) and one for each correctly recalled ﬁnal word (omission or addition of the plural morpheme was not taken into account).  Individual scores for grammar, sense, and recall were combined to form a composite score.  The maximum score possible for each section was 48, and the maximum composite score was 144.  PSTM.  Two PSTM tests (L1 and L2) were developed by the author (see Grey, Cox, Seraﬁni, & Sanz, 2015.  Grey, Williams, & Rebuschat, 2014, for implementation of the L1 PSTM) based on the PSTM test developed by Mackey, Philp, Fujii, Egi, and Tatsumi (2002).  Whereas L1 PSTM measures participants’ phonological processing and storage ability in the learner’s native language, L2 PSTM measures participants’ phonological processing and storage ability for nonnative phonotactic patterns (Grey et al. , 2015).  The tests consisted of two lists of 16 pairs of nonwords (32 in total in each test), which varied in the number of syllables.  In each of the tests, there were 4 sets of 3 pairs of words (with 3, 4, 5, and 6 syllables), and two sets of 2 pairs of words (with 7 and 8 syllables).  In other words, the number of syllables increased by 1 every 3 pairs in the ﬁrst four sets, and every 2 pairs in the last two sets.  The 32 items in each test were presented aurally in pairs, and participants had to repeat the two nonwords after a tone, which was presented with a 2-s delay.  The total amount of time spent on the tests was 10 min (5 min each).  One point was assigned for each nonword correctly recalled or for each nonword that differed by no more than one syllable from the original nonword.  The total possible score was 32 for each test.  The scores were considered independently in the analyses.  Language analytic ability and RM.  Participants were administered the words in sentences and paired associates tests of the MLAT.  The researcher chose to report these two subtests rather than all subtests of the MLAT because these two subtests have frequently been shown to correlate with language learning.  In the words in sentences, participants had to identify the role played by a word in a sentence by associating it with a word that played the same role in a different sentence.  This subtest contained 45 sentences.  The paired associates subtest required learners to memorize 24 words in 2 min.  After the 2 min, participants completed a practice exercise.  They were allowed to look back at the vocabulary during this practice exercise, but not during the 24 questions in the subsequent test.  One point was assigned for each correct item on each subtest, so that a ﬁnal score was obtained for the two tests separately.  ANALYSES AND RESULTS.  A one-way analysis of variance (ANOVA) was used to compare cognitive scores from the two groups.  The analyses indicated that there was no difference between groups for any of the cognitive measures.  LAA, F (1, 54) = 2. 77, p = . 10.  RM, F (1, 54) = 2. 60, p = . 11.  WM, F (1, 55) = 0. 49, p = . 48.  L1 PSTM, F (1, 55) = 0. 08, p = . 78.  L2 PSTM, F (1, 55) = 0. 63, p = . 43.  Next, a two-way mixed design multivariate ANOVA was conducted in order to compare performance between treatments across time.  Treatment (+MF, –MF) was entered as the between-subjects factor and time (pretest, posttests, and delayed tests) as the within-subjects factor.  The three language measures (WI, AI, and GJT) were entered as dependent variables.  The results indicated that there was a main effect for treatment, F (3, 46) = 3. 42, p < . 05 (partial η² = 0. 18), and time, F (6, 43) = 20. 58, p < . 05 (partial η² = 0. 74), and an interaction Time× Treatment, F (6, 43) = 6. 14, p < . 05 (partial η² = 0. 46).  Taking into account these results and the means in Table 1, it appears that regardless of language measure, participants in the +MF performed differently and better than the –MF across time.  Subsequent separate univariate ANOVAs on the outcome variables tested between-subjects effects regardless of time.  The results revealed signiﬁcant main effects for treatment on the WI, F (1, 48) = 10. 51, p < . 05 (partial η² = 0. 18), and AI, F (1, 48) = 5. 04, p < . 05 (partial η² = 0. 09), but not on the GJT, F (1, 48) = 0. 53, p = . 47 (partial η² = 0. 01).  In other words, when taking together scores on pretest, posttest, and delayed test, results on the WI and AI tests differed by treatment.  The GJT results, on the contrary, revealed no signiﬁcant difference between treatments.  Next, we looked at estimated marginal means to determine the nature of the interaction.  Pairwise comparisons revealed signiﬁcant differences between treatments for the WI and AI posttests, but not for the GJ posttest.  In delayed test results, however, there were no signiﬁcant differences between groups for any of the tests (see Table 2) Following these analyses, 12 multiple regressions were conducted on posttest and delayed WI, AI, and GJ test scores in order to ﬁnd out to what degree aptitude predicted language development in each treatment separately.  All possible predictors were added, and the model selection procedure was based on best subsets with adjusted R2 as a criterion for entry or removal.  Correlation analyses (see Table 3) revealed that L1 PSTM and L2 PSTM correlated strongly with one another.  For that reason, they were not entered together in the same model.  Next, we report only the signiﬁcant results obtained for each treatment separately.  Signiﬁcant results for the +MF treatment The results of the regression analysis completed on the WI posttest revealed that LAA and L2 PSTM explained 32. 6% of the variance, R2 = 32. 6%, F (2, 30) = 8. 75, p < . 01.  It was found that LAA (β = 0. 15, p < . 01) signiﬁcantly predicted WI posttest scores and that L2 PSTM (β = –0. 21, p < . 05) also predicted WI posttest scores, but negatively.  Results on the WI delayed test revealed that LAA explained 18% of the variance, R2 = 18%, F (1, 31) = 7. 98, p < . 01, and signiﬁcantly predicted test scores (β = 0. 20, p < . 01).  Further analyses on the AI delayed test revealed that LAA also explained 22% of the variance, R2 = 22%, F (1, 29) = 9. 41, p < . 01, and signiﬁcantly predicted test scores (β = 0. 24, p < . 01).  As for results on the GJ posttest, WM and RM explained 30% of the variance, R2 = 29. 7%, F (2, 29) = 7. 54, p < . 01, and signiﬁcantly predicted test scores (for WM, β = 0. 13, p < . 01, and for RM, β = 0. 27, p < . 05).  Finally, analyses conducted on the GJ delayed test revealed that WM explained 30% of the variance, R2 = 30. 4%, F (1, 30) = 14. 53, p < . 01, and signiﬁcantly predicted test scores (β = 0. 17, p < . 05).  Signiﬁcant results for the –MF treatment.  The only signiﬁcant result for the –MF treatment appeared when conducting regression analyses on the AI posttest, which revealed that RM explained 13% of the variance, R2 = 13%, F (1, 22) = 4. 45, p < . 05, and signiﬁcantly predicted test<Conclusion> DISCUSSION.  The current study investigated the role of different aptitude abilities (RM, LAA, WM capacity, and PSTM) in the development of a new language under two learning conditions that differed in the presence or absence of metalinguistic information provided as part of feedback during input-based practice.  As the results indicate, although learners in the +MF treatment outperformed those in the –MF treatment in immediate aural and WI tests, both treatments achieved similar levels of performance in all three delayed tests.  Thus, we explore the role of aptitude in language development under two conditions that differed in the amount of grammar information provided, but achieved comparable long-term results in each test.  Supporting previous literature on ATI (Erlam, 2005. 
 When speakers talk, they are normally trying to give linguistic form to a notion they have in their heads that they wish to implant in their interlocutors’ heads.  Insofar as speakers can and do describe things that they are seeing either at that very moment or with their minds’ eyes, it is logical to think that visual characteristics will have an inﬂuence on speaker choices regarding most obviously the content, but also the ﬁnal form of their descriptive utterances.  Vision has been found to inﬂuence language in many ways.  For example, a character who is looked at ﬁrst for perceptual reasons is more likely to be mentioned ﬁrst (e. g. , Gleitman, January, Nappa, & Trueswell, 2007.  Myachykov, Garrod, & Scheepers, 2012.  Myachykov, Thompson, Garrod, & Scheepers, 2011).  looks to characters in an image have been consistently found to predict mention of the ﬁxated characters (e. g. , Coco & Keller, 2012.  Coco, Malcolm, & Keller, 2014.  Grifﬁn, 2001) and their properties (Haskell, 2005.  Meyer, van der Meulen, & Brooks, 2004.  van der Meulen, 2001).  and visual content inﬂuences choice of referring expression (Fukumura, van Gompel, & Pickering, 2010).  However, speakers are not always describing a scene, and even when they are, some of the information conveyed is not straightfordwardly attributable to something the speakers perceive or have a perceptual memory of.  Moreover, the information derived from the visual system is unlikely to be in a format that can be directly transferred to the linguistic system.  Some kind of translation is required (Jackendoff, 1987).  In short, the blueprints for sentences are likely to come from a conceptual representation of the perceived event, rather than from the perceived event itself (Bunger, Papafragou, & Trueswell, 2013.  Vogels, Krahmer, & Maes, 2013).  Although most researchers will probably agree with the previous statement, some explanations of perceptual inﬂuences on language production seem to either disregard the existence of an intermediate level of event conceptualization or confound it with sentence preparation under the implicit assumption that what you see is what you say (Ibbotson, Lieven, & Tomasello, 2013.  Montag & MacDonald, 2013.  Myachykov et al. , 2012.  Myachykov, Thompson, et al. , 2011), rather than determining what you may want to say.  More speciﬁcally, looks to elements in a scene are linked directly with the building blocks of sentence production rather than with the way the scene is apprehended (see, e. g. , Myachykov, Posner, & Tomlin, 2007, p.  464, their ﬁgure 2.  Myachykov, Thompson, Garrod, et al. , 2011).  In consequence, the fact that speakers’ gazes are drawn to a speciﬁc object and this object is then chosen as the syntactic subject of the ﬁnal description is taken to mean that the starting point in sentence production is a lexical item rather than a syntactic frame (Gleitman et al. , 2007.  for a detailed description of the “syntactic planning starting point” debate, see Bock, Irwin, & Davidson, 2004).  In truth, however, even when perceptual salience correlates with choice of starting point in a sentence, it is possible that the perceptual properties are inﬂuencing how the event is conceptualized rather than linguistic planning directly (Vogels et al. , 2013).  Cueing a participant in a scene may be one way of anchoring the way the event is interpreted, which could make the cued character then become the topic of the linguistic message, what Bock and Ferreira (2014) call the “aboutee,” and thus be the ﬁrst mentioned noun by virtue of its conferred conceptual status.  This would be similar to the special status conferred by other conceptual properties such as animacy, which also inﬂuences linguistic choices (Ant´on-M´endez, Gerfen, & Ramos, 2016.  Branigan, Pickering, & Tanaka, 2008.  Brawley, 2012.  Hickmann, Taranne, & Bonnet, 2009.  Prat-Sala & Branigan, 2000).  To determine which of the two mechanisms, scene conceptualization or lexical activation, is responsible for the observed effects of visual salience on linguistic output, it would be necessary to pitch the visual manipulation against another manipulation thought to affect at least one of these two levels of processing.  for example, a linguistic prime.  Myachykov et al.  (2012) conducted such an investigation.  In their Experiments 1 and 2, the researchers looked at the proportion of active descriptions of depicted transitive events (e. g. , a cowboy punching a boxer) after a linguistic prime consisting of either a matching or a nonmatching verb (e. g. , punch vs.  kiss), and a visual prime in the form of a dot directing attention to the location of one of the two characters prior to the image appearing on screen.  They found that visually cueing the agent of the event (e. g. , the cowboy) increased the proportion of active descriptions but only when the linguistic prime was the nonmatching irrelevant verb (e. g. , kiss).  For the authors, this interaction points to the effect of perceptual manipulations on syntactic choice over and above the effect of a verbal prime.  There is an alternative interpretation of these results, however, since there was an imbalance between the two kinds of priming in Myachykov et al. ’s design.  the visual manipulation primed one or the other participants in an unambiguous event, but the linguistic one either primed or did not prime the event.  The interaction could thus be due to the visual cue having an effect only in the absence of a “useful” linguistic one, while when there is a matching linguistic prime, the visual cue did not make any difference.  To create a more balanced design, the scenes to be described should allow linguistic priming in both directions, something that can best be achieved by the use of perspective predicates (Gleitman et al. , 2007).  To investigate whether perceptual manipulations inﬂuence sentence production directly through lexical access, the following experiments were designed to look for the effects that visual salience would have on sentence production if it inﬂuenced linguistic processing directly by determining order or mention or argument assignment.  Speciﬁcally, the experiments looked for the effects of visual priming on scenes that can be described from two complementary perspectives (e. 
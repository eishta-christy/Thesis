I N T R O D U C T I O N.  Human communication is multimodal, including gestures.  Gestures are visible actions of body parts (Kendon, ) and constitute a crucial part of conversation.  Co-speech gestures accompany spoken speech.  They contribute to felicitous communication by facilitating listeners’ comprehension of a spoken message (Beattie & Shovelton, .  Hostetter, .  Kendon, ) and help speakers retrieve information stored in the mental lexicon (Frick-Horbury & Guttentag, .  Krauss, Chen & Gottesman, .  Ruiter, ).  The close relationship between gesture and speech and their mutual influence are widely recognized.  Accounts of embodied cognition assume that motor actions, such as observing a speaker gesturing, enhance memory and learning (Madan & Singhal, ).  Gestures are classified into different types.  Here, we focus on iconic hand gestures, which capture meaning aspects of the entity that is conveyed by the gesture (McNeill, ), for example flapping hands representing a bird flying.  Iconic gestures have been suggested to facilitate word learning.  It is argued that iconic gestures are less arbitrary than most spoken symbols.  The visuospatial aspects of gesture help process the accompanying speech and lead to strengthened memory traces and deeper conceptual understanding (Hostetter, .  So, Chen-Hui & Wei-Shan, ).  A comprehensive review of the existing literature (Hostetter, ) proposed that gestures are particularly helpful to children.  The focus of the present study is on word learning in typically developing (TD) children and in children with specific language impairment (SLI).  Previous research indicated a gesture advantage in children with SLI as compared to their TD peers such that they show stronger associations between gesture and language (Botting, Riches, Gaynor & Morgan, ), and benefit more from gesture input for pragmatic comprehension (Kirk, Pine & Ryder, .  Lavelli, Barachetti & Florit, ).  So far, this has not been demonstrated for word learning.  Therefore, it is interesting to investigate the influence of gestures on word learning in typically developing and language impaired populations.  Word learning in children with SLI.  SLI is defined as a developmental language disorder in the absence of any identifiable reason for the disorder (Bishop, .  Leonard, ).  It is generally agreed that the population is heterogeneous and that children with SLI show various deficits in language, including slow acquisition of the lexicon and grammar, and limited comprehension and production of vocabulary or grammatical forms (Bishop & Snowling, .  Conti-Ramsden & Botting, .  Leonard, ).  Limited processing capacities and difficulty with sustained attention are reported as well (Alt, Myers & Alt, .  Ebert & Kohnert, .  Eichorn, Marton, Campanelli & Scheuer, .  McKean, Letts & Howard, .  Sheng & McGregor, ).  Problems with word learning are often part of the characteristics associated with SLI.  Word learning is a process in which word representations are gradually established, starting from an incomplete representation after first perceiving the new form–referent link through fast mapping until the word is represented and stored completely through slow mapping (Horst & Samuelson, .  Justice, Meier & Walpole, ).  Children with SLI are reported to have weak word knowledge, i. e.  weak semantic and phonological representations, compared to peers.  Thereby, both fast and slow mapping are affected (Alt et al. , .  Gray, .  McKean et al. , ).  Given that the vocabulary deficiencies seem to reflect immaturities in semantic representation (McGregor, Newman, Reilly & Capone, .  Sheng & McGregor, ), methods to support word learning in children with SLI are desirable.  Below, we summarize findings regarding the role of iconic gesture as a means of enhancing word learning in TD children and children with SLI.  Contribution of observing iconic gesture to children’s word learning.  For word learning, children use a number of cues, gestures among them.  To derive benefit from iconic gestures, two mechanisms are important.  First, the child has to be capable of detecting the meaning conveyed by the gesture.  While still fragile in toddlerhood, the ability to derive meaning from iconic gestures develops at three years of age and is acquired by age .  to .  (Namy, Campbell & Tomasello, .  Novack, Goldin-Meadow & Woodward, .  Stanfield, Williamson & Özçaliṣkan, .  Tolar, Lederberg, Gokhale & Tomasello, ).  Preschool children can also learn from arbitrary gestures, but once they are able to recognize iconicity they learn from iconic gestures more readily than from arbitrary ones (Marentette & Nicoladis .  Namy et al. , ).  Besides, some types of iconic gestures appear to be easier to identify than others, for example gestures depicting actions associated with an object (Hodges, Özçaliṣkan & Williamson, ), and gestures showing how an object is handled are recognized earlier in development than gestures based on the shape of an object (Tolar et al. , ).  Second, the child has to be able to process and integrate multimodal information.  While typical word learning implies mapping a spoken word onto a referent, word learning paired with gestures requires additional cognitive demands such that both a spoken word and a gesture have to be mapped onto the referent (Puccini & Liszkowski, ).  It has been shown that children at age three are able to integrate information presented in iconic gesture and speech (Sekine, Sowden & Kita, ).  Evidence supporting the notion that observing iconic gestures facilitates word learning for a range of word classes comes from studies with young TD children.  It has been demonstrated that seeing iconic gestures helped preschool children to focus on a particular aspect of novel verbs and thereby enhanced learning their meaning (Goodrich & Hudson Kam, .  Mumford & Kita ).  Capone and McGregor () showed that co-speech iconic gestures exemplifying the shape and function of novel objects improved word retrieval in toddlers.  Moreover, iconic shape gestures were more effective than pointing gestures (Capone Singleton, ).  McGregor, Rohlfing, Bean, and Marschner () taught two-year-olds the preposition under either with or without iconic gestures.  At delayed post-test, children showed a more robust and abstract knowledge of the meaning when the words were paired with a gesture.  Moreover, it was found that observing iconic gestures was particularly effective when spoken messages were complex (McNeil, Alibali & Evans, ).  Observing iconic gestures appears to improve immediate comprehension and, in particular, benefit slow mapping (McGregor et al. , .  Munro, Baker, McGregor, Docking & Arciuli, ).  Two studies suggest that iconic co-speech gestures can serve to scaffold word learning in children with SLI.  Work by Ellis Weismer and Hesketh () has shown that in a fast mapping task children with SLI as well as TD children understood novel spatial terms better when the words were trained with iconic gestures compared to words trained without additional input.  However, there were no effects on naming.  Lüke and Ritterfeld () expanded this work by additionally investigating slow mapping.  Effects of observing iconic shape gestures on the learning of names for cartoon characters were compared to a no-gesture condition.  Contrary to Ellis Weismer and Hesketh’s () study, no immediate advantage of the iconic gesture condition emerged.  However, during slow mapping children showed a gesture benefit for naming – but not for comprehension.  The authors of both studies conclude that observing iconic gestures leads to more efficient word learning in children with SLI.  Yet, generalization of this conclusion has serious limitations.  First, stimuli used in the studies (novel words for spatial terms, whose meaning children already knew, and proper names for cartoon characters) are not representative of the words children acquire.  Second, the number of children with SLI in the experimental groups was rather small (eight and ten children, respectively).  Moreover, in both studies the control condition was merely an absence of gesture, involving no additional cues beyond speech.  Hence, word learning conditions differed with respect to their processing demands (So et al. , .  Yap, So, Yap & Tan, ).  Whilst in the iconic learning condition both a spoken word and a gesture had to be mapped onto the referent, the control condition required the child to process auditory information only (Puccini & Liszkowski, ).  In a ‘gesture vs.  no-gesture’ design, it remains unclear whether children benefit from iconic gestures due to the specific information conveyed by the gesture, or rather because the additional visual input directed children’s attention to the target words and thus improved learning.  In order to show that iconic gestures do more than focus attention, demonstration of an iconic gesture benefit over a control condition that goes beyond a no-gesture condition is required.  However, studies comparing two different gesture types in word learning (in terms of mapping a lexical form and semantics) are rare.  Lüke and Ritterfeld () conducted a fast mapping experiment and found that both iconic and arbitrary gestures had a beneficial effect on TD preschoolers’ initial word learning.  Capone Singleton () demonstrated enhanced learning of novel nouns paired with iconic gestures as compared to pointing gestures.  Pointing gestures are stationary gestures which scaffold referential understanding by focusing children’s attention on the referent whose lexical form they are learning (Novack et al. , ), provided the referent is in the immediate environment.  Iconic gestures, however, require attention to hand movement and represent referents (Puccini & Liszkowski, ).  Results led Capone Singleton () to suggest that iconic gestures enrich semantic learning, establish more robust word knowledge, and in this way make word learning more efficient than pointing gestures do.  The current study set out to substantiate and expand these findings.  <Middle> Current study.  For this purpose, we designed a study to compare the learning of unknown words (nouns and verbs) in a within-subjects design under two gesture conditions.  In the experimental condition, new words were taught with iconic gestures.  To ensure that a potential iconic gesture advantage does not merely reflect enhanced attention to the target word, we applied a control condition, in which the target words were paired with an attention-directing gesture in the form of a raised forefinger in front of the upper body.  Such a gesture does not convey the semantic meaning of the referents, and resembles pointing gestures in that it is stationary and visually guides attention.  At the same time, the control gesture covers functions of iconic gestures, such that it directs attention to hand movement, nevertheless lacking the specific property of iconic gestures, namely visually capturing meaning aspects of the referent.  Rather, the control gesture guides listeners to attend to particular parts of the utterance, increases the salience of the word, and thus serves a metalinguistic purpose.  Such a control condition enabled us to investigate whether iconic gestures do more than focus attention.  This approach allowed us to compare two conditions where both the spoken word and a gesture have to be mapped onto the referent.  In a subsequent control experiment, we modified the control condition by using different arbitrary gestures instead of the constant attention-directing gesture.  We investigated the ability to learn words in two gesture conditions in TD children and children with SLI, and assumed that children of either group could master the task. 
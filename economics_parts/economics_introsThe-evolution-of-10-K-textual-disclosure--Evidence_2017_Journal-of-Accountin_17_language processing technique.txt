 1.  Introduction  Investors, preparers, regulators, and standard setters have expressed concern that corporate disclosure has become longer,  more redundant, less readable, less speciﬁc, and more boilerplate over time ( Li, 2008.  KPMG, 2011.  SEC, 2013 ).  In 2013, the  SEC began a comprehensive review of regulation with the intent of identifying excessive, unduly complex, and redundant  disclosure ( SEC, 2013 ).  Similarly, the FASB has an ongoing agenda project, the Disclosure Framework, evaluating the effectiveness of textual disclosure ( FASB, 2012 ).  A variety of explanations have been offered for why disclosure might be changing  over time including increases in litigation concerns, business complexity, globalization, regulation, and new mandatory disclosures ( KPMG, 2011.  SEC, 2013.  Monga and Chasan, 2015 ).  In this paper we quantify a variety of 10-K disclosure attributes  and provide initial descriptive evidence on trends in these attributes over time.   While there is a substantial academic literature on trends in the characteristics of quantitative accounting data (particuthe magnitude, economic determinants, speciﬁc content, and attributes of trends  larly earnings and book value) over time,  in textual disclosure have received less attention.  At least in part, this likely reﬂects the challenge in assessing the content  of 10-K textual disclosure and in categorizing and quantifying disclosure for a large number of lengthy, complex documents,  especially given that disclosure of a given topic often appears in multiple sections of the 10-K and any given passage often  combines multiple topics.   In many ways, the issues in assessing 10-K content are similar to those faced in other literatures.  For example, researchers  in journalism have been interested in trends in coverage of the New York Times ( Blei, 2012 ), those in literature in understanding topical trends in poetry ( Rhody, 2012 ), in politics understanding trends in Senate discourse ( Grimmer, 2010 ), in  history understanding historical trends using the content of State Department cables ( Chaney et al. , 2015 ), and in science  understanding topical trends in journals such as Science ( Blei and Lafferty, 2007 ).  In all of these domains, the challenge is  in analyzing trends in corpuses far too large for humans to manually review and to summarize them in a way that is easily  interpretable.   Following that literature, we use a natural language processing technique, Latent Dirichlet Allocation (LDA), to understand the changing content of 10-Ks.  3 LDA is a Bayesian computational linguistic technique that identifies the latent topics in a corpus of documents. 